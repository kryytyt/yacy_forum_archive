Hilfe für Einsteiger und Anwender • Crawler und Solr getrennt: Solr-Cloud?
==========================================================================

Date: 2015-07-01 00:51:31

Hallo!\
\
Vor den Fragen die Ausgangssituation:\
\
Ich bin dabei, zu einem bestimmten Wissensgebiet eine Suchmaschine
aufzusetzen, die freeworld natürlich mit unterstütz. Wegen der
unterschiedlichen Auslastungen und um die Response auf Suchanfragen zu
optimieren, habe ich das System in mehrere System-Teilkomponenten auf
verschiedene Rechner getrennt:\
\
Crawling (2 Systeme)\
Solr (1 System)\
Suchoberfläche (1 System)\
\
Die beiden Crawling-Systeme sollen gleichzeitig auf die Solr-Datenbank
arbeiten. Obwohl die Crowlings bei der ersten vollständigen Erfassung
der Quellen im Robinson-Modus arbeiten, um keine Rechenzeit zu
vergeuden, sammeln sie durch eingeschalteten \"support peer-to-peer
index transmission (DHT RWI index)\" die Informationen, um im
nachfolgenen (dauerhaften Modus) die Informationen mit anderen Peers zu
teilen. Robinson ist also nur temporär zu Beginn.\
\
Beide Systeme arbeiten auf ein Solr auf einem separaten Rechner.\
\
Um nun die Suche nicht von der Auslastung mit Crawls gar zu sehr
abhängig zu machen, wird die Suchseite durch ein weiteres System bereit
gestellt, dass auf Solr zugreift (nur lesend). Prinzipiell kenne ich die
Infos auf den ganzen Yacy-Webseiten. Sie haben mir schließlich geholfen,
die Teilsysteme zum Laufen zu bekommen. Einige Fragen bleiben trotzdem,
bevor ich das als dauerhaftes Produktivsystem freigeben möchte:\
\
Fragen:\
\
1) Solr kann man, wie auf den Yacy-Webseiten beschrieben, als einzelnes
System aufsetzen oder als Cloud. Wann benötigt man die Cloud-Variante?
Schon, wenn ich wie hier mit zwei Crawlern auf eine Solr-Datenbank
arbeite? Oder wann sonst? In meinem beschriebenen Fall?\
\
2) Wenn ich einen Crawl auf der ersten Crawing-Maschine starte und einen
Tag später (nachdem also schon ordentlich gecrawlt und indiziert wurde)
auf dem zweiten System den gleichen Crawl einrichte, um ihn dort ab
jetzt aller 6 Stunden auszuführen, dann wird dort offenbar noch mal in
aller Tiefe ein Crawling ausgeführt. Ein Fehler? Ich hatte erwartet: Das
erste System crawlt in die Tiefe, das zweite System beginnt auf der
Startseite und geht nicht tiefer, da bereits alle Seiten vom anderen
System in die Solr-Datenbank übertragen wurden. Mein Ziel: Auf dem
ersten System erstmalig einen vollständigen Domain-Crawl. Das zweite
System prüft nur noch die Startseite aller 6 Stunden und crawlt, was
dort neu erscheint. -\> Im Moment sieht es so aus, dass beide Systeme
alles vollständig crawlen. Obwohl die Seiten bereits vom ersten System
im Solr indiziert sind, macht das zweite Crawling-System ein weiteres
vollständiges Crawling. Wie ist das richtig? Wie muss das sein? Was
mache ich falsch?\
\
3) Die beiden Crawl-Systeme arbeiten auf ein Solr, dass auf einem
anderen System installiert ist. Fährt nun das Solr aus einem bestimmten
Grund herunter, ist also für die Crawler nicht mehr erreichbar: Was
passiert? Was machen die Crawler? Es sieht aus, dass sie nun auf eine
lokale (die in YaCy eingebettete Solr-) Datenbank crawlen. Ist das so?
Wie kann ich das organisieren, dass die Crawler ihre Information
zurückhalten bzw. das Crawling stoppen, bis wieder das Solr am Netz ist?
Oder übertragen sie später, wenn die entfernte SOlr-Datenbank wieder
online ist, den Inhalt dort hin?\
\
Viele Grüße\
Frank

Statistik: Verfasst von
[fherb](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9031)
--- Di Jun 30, 2015 11:51 pm

------------------------------------------------------------------------
