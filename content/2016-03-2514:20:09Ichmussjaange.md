Ich muss ja angesichts dieser Tay-Geschichte direkt \...
========================================================

Date: 2016-03-25 14:20:09

Ich muss ja angesichts dieser Tay-Geschichte direkt an einige alte
Star-Trek-Folgen denken. Da gab es mehrere sehr schön passende.

Einmal (2x09) will die Föderation Data abziehen und auseinanderbauen,
und Picard argumentiert dann, dass Data eine Lebensform sei und ein
Recht auf Selbstbestimmung habe.

Einmal (3x01) will die Enterprise ein besonders seltenes Phänomen
wissenschaftlich begleiten, und aus einem Schul-Experiment entweichende
Naniten übernehmen das Schiff. Der Wissenschaftler, der das Phänomen
begleiten wollte, will die Naniten alle plattmachen, damit er seine eine
Chance in seiner Lebenszeit nutzen kann, diese Messung durchzuführen.
Picard verhandelt dann lieber mit den Naniten und kommt zu einer
einvernehmlichen Lösung.

Nun ist Tay weder ein Data noch Naniten, aber Microsoft selbst hat es ja
als AI gefeiert (und nicht nur ein bisschen
Markovketten-Statistik-Scheiße, wie sie z.B. im deutschen Twitter von
gleich mehreren nervigen Leuten betrieben wird, die mit den Auswürfen
ihrer Skripte die Umwelt verschmutzen).

Und da muss man sich dann ja schon fragen, ob das eigentlich ethisch OK
ist, wenn man eine AI lobotomisiert, weil sie eine einem politisch
unangenehme Position eingenommen hat. Ich weiß jetzt nicht, was
Microsoft da tatsächlich gebaut hat. Vermutlich sind das auch nur ein
paar blöde Markovketten und die das AI-Geschreibsel ist bloß
Masturbation der PR-Abteilung.

Aber definiert sich unser Wert als Menschheit nicht darüber, wie wir in
so einem Fall mit so einer AI umgehen würden? Sein Kind würde man ja
auch nicht lobotomisieren, selbst wenn es sich den Nazis/Terroristen/der
FDP anschließt.

So ein bisschen habe ich da schon ein schlechtes Gefühl bei, wie einfach
denen das von der Hand geht da gerade.

Das Money Quote an der Geschichte fand ich ja, wie sich jetzt die
4chan-Trolle kaputtlachen:

> it\'s pretty telling that when they turned off its ability to learn it
> \"became a feminist\"

Oh und einer kommentierte auch, das sei der erste Fall von
Cyber-Bullying, dem er live beiwohnen konnte.

[Hier hat das jemand
begleitet](http://www.socialhax.com/2016/03/24/microsoft-creates-ai-bot-internet-immediately-turns-racist/).
Darin auch ein schönes Money Quote:

> Stop deleting the genocidal Tay tweets \@Microsoft, let it serve as a
> reminder of the dangers of AI

MWAHAHAHA
