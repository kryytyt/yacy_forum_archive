En:Debian High Availability
===========================

Date: 2013-03-06 12:02:45

fixed the downtime replication: do not copy the api.bheap file to
prevent that the second peer crawls

← Nächstältere Version

Version vom 6. März 2013, 11:02 Uhr

(2 dazwischenliegende Versionen von einem Benutzer werden nicht
angezeigt)

Zeile 53:

Zeile 53:

 

<div>

  \~/yacy0/stopYACY.sh  

</div>

 

<div>

  \~/yacy0/stopYACY.sh  

</div>

 

 

−

<div>

Now the DATA directory in \~/yacy0 was ceated and we can clone this to
yacy1

</div>

\+

<div>

Now the DATA directory in \~/yacy0 was ceated and we can clone this to
yacy1[, run]{.underline}

</div>

−

<div>

  cp -R \~/yacy0/DATA \~/yacy1/DATA && sed \"s/port=8090/port=8091/\" -i
\~/yacy1/DATA/SETTINGS/yacy.conf

</div>

\+

<div>

[]{.underline}

</div>

 

\+

<div>

  cp -R \~/yacy0/DATA \~/yacy1/DATA && sed \"s/port=8090/port=8091/\" -i
\~/yacy1/DATA/SETTINGS/yacy.conf [&& rm -f
\~/yacy1/DATA/WORK/api.bheap]{.underline}

</div>

 

 

 

<div>

The second peer needs a different port. Therefore the sed command
replaces the port 8090 by 8091.

</div>

 

<div>

The second peer needs a different port. Therefore the sed command
replaces the port 8090 by 8091.

</div>

−

<div>

~~Please write~~ this command ~~line to~~ a file \~/replicate\_all.sh
~~so you can easily run this again~~.

</div>

\+

<div>

[We also do not want that the second peer does the same crawling as
configured in yacy0, therefore we also delete the api file.]{.underline}

</div>

−

<div>

This is of course only a tool for a downtime replication. We will see
how to ~~to~~ an uptime replication later.

</div>

\+

<div>

[We need]{.underline} this command [later, therefore we
create]{.underline} a file \~/replicate\_all.sh [with the following
content:]{.underline}

</div>

 

\+

<div>

[\~/yacy0/stopYACY]{.underline}.[sh && \~/yacy1/stopYACY.sh]{.underline}

</div>

 

\+

<div>

[cp -R \~/yacy0/DATA \~/yacy1/DATA && sed \"s/port=8090/port=8091/\" -i
\~/yacy1/DATA/SETTINGS/yacy.conf && rm -f
\~/yacy1/DATA/WORK/api.bheap]{.underline}

</div>

 

\+

<div>

[\~/yacy0/startYACY.sh && \~/yacy1/startYACY.sh]{.underline}

</div>

 

\+

<div>

This is of course only a tool for a downtime replication. We will see
how to [do]{.underline} an uptime replication later.

</div>

 

 

 

<div>

We can now start both peers

</div>

 

<div>

We can now start both peers

</div>

 

<div>

  \~/yacy0/startYACY.sh && \~/yacy1/startYACY.sh

</div>

 

<div>

  \~/yacy0/startYACY.sh && \~/yacy1/startYACY.sh

</div>

 

\+

<div>

[]{.underline}

</div>

 

\+

<div>

[===Adding a https Gateway in Front of the Administration
Interface===]{.underline}

</div>

 

\+

<div>

[Security is part of an availability strategy and therefore all
production modifications should be made through a secure interface. To
apply a ssl encryption in front of the primary peer, follow the
instructions in \[\[En:YaCyOverHTTPS\]\]]{.underline}

</div>

 

 

 

<div>

===Auto-Start for YaCy===

</div>

 

<div>

===Auto-Start for YaCy===

</div>

Zeile 182:

Zeile 190:

 

 

 

<div>

===Usage of this High Availability Configuration===

</div>

 

<div>

===Usage of this High Availability Configuration===

</div>

−

<div>

The public search interface is at http://{yourhost}:8100 (or
http://{yourhost} if you set the reverse proxy port to 80). Thats the
URL you propagate as the search interface. To administrate the search
interface, use the address http://{yourhost}:8090. Every time you
changed the search interface configuration (like a new skin or different
ranking), you must do a full (downtime) replication using the script
\~/replicate\_all.sh (shut down both peers before this) but it would be
easy to make this as a high-availability task (shut down yacy0 first,
tar the DATA dir, start up yacy0, shut down yacy1, extract DATA to
yacy1, start up yacy1). There is no need to do this for index updates
after you started a web crawl, because the index replication process
does that once a day automatically. You might want to do this more often
by adjusting the line in crontab.

</div>

\+

<div>

The public search interface is at http://{yourhost}:8100 (or
http://{yourhost} if you set the reverse proxy port to 80). Thats the
URL you propagate as the search interface. To administrate the search
interface, use the address http://{yourhost}:8090[, or better:
https://{yourhost} if you followed the instructions in
\[\[En:YaCyOverHTTPS\]\]]{.underline}.

</div>

 

\+

<div>

 

</div>

 

\+

<div>

[Please note that http://{yourhost} is the gateway for the load balancer
while https://{yourhost} is only the access point for the yacy0-peer and
administration tasks.]{.underline}

</div>

 

\+

<div>

 

</div>

 

\+

<div>

Every time you changed the search interface configuration (like a new
skin or different ranking), you must do a full (downtime) replication
using the script \~/replicate\_all.sh (shut down both peers before this)
but it would be easy to make this as a high-availability task (shut down
yacy0 first, tar the DATA dir, start up yacy0, shut down yacy1, extract
DATA to yacy1, start up yacy1). There is no need to do this for index
updates after you started a web crawl, because the index replication
process does that once a day automatically. You might want to do this
more often by adjusting the line in crontab.

</div>
