English â€¢ Re: PPM limitations in YaCy?
======================================

Date: 2014-11-12 15:01:48

There is actually a hardcoded limitation to 2 documents per second for
the same domain. This is done in connection with a proper identification
of the crawler as \'yacybot\'. The combination of the limitation and the
identification of the crawler is promise to web hosters that YaCy is a
good behaving robot and does not overload web services.\
\
Furthermore we fully support the robots.txt standard which may demand an
even slower crawling.\
\
If you start several crawls for different domains, this factor adds up,
i.e. if you start 5 crawls then YaCy loads 10 web pages per second, but
the limitation for a single domain is always the same. For most cases
this is sufficient because you can load 172800 documents for a single
domain each day. Most domains do not have so much documents, so this
should work for most of us.\
\
If you want to index really large domains like the wikipedia you can
import the wikipedia XML dump. This does up to 60000 ppm.\
\
If you run YaCy in the intranet then the limitation is removed for
intranet addresses. I tested this with more than 10000 ppm. Speed is not
a problem for YaCy, but for most hosters.

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Mi Nov 12, 2014 3:01 pm

------------------------------------------------------------------------
