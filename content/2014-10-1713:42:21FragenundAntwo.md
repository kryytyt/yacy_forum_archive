Fragen und Antworten • Re: YaCy als Proxy?
==========================================

Date: 2014-10-17 13:42:21

Hallo,\
\

> <div>
>
> TmoWizard hat geschrieben:\
> Es gibt dort außer mir
> [([[P-C-I]{style="font-weight: bold"}]{style="color: #40BF00"})]{style="font-style: italic"}
> kaum jemanden, bei denen der Crawler überhaupt erlaubt oder aktiv ist!
> Obwohl ich mit diesem Rechner nebenbei auch arbeite habe ich YaCy so
> eingestellt, damit auch andere etwas davon haben.\
>
> </div>

Dort ist die Rede vom \"akzeptieren von Remote-Crawl-Aufträgen\", das
meint das der jeweilige Peer bereit ist von anderen Peers Crawl-Aufträge
anzunehmen damit die Crawl-Last auf mehrere Peers verteilt werden kann.
Dieses Feature ist meiner Meinung nach das Feature einer
[verteilten]{style="text-decoration: underline"} Suchmaschine. Aus
technischer Sicht sollte dieses Feature bei allen Peers per default
eingeschaltet sein (wenn das Problem mit dem User-Agent gelöst wäre)
aber aus rechtlicher Sicht (wegen der Haftung für die eigene IP-Adresse
wenn diese plötzlich in den Logs von Servern auftaucht auf denen man
besser nicht sein sollte) ist es in Ländern wie Deutschland faktisch
unmöglich dieses Feature zu aktivieren.\
\
Ob der betreffende Peer den eigenen Crawler mit eigenen Jobs beauftragt
ist in den von Dir verlinkten Listen nicht ersichtlich (diese
Information verbreitet kein YaCy-Peer).\
\

> <div>
>
> TmoWizard hat geschrieben:\
> Sinn und Zweck einer Suchmaschine ist ja wohl, daß sie so viele
> Suchtreffer wie möglich ergibt.\
>
> </div>

Ganz genau, und deswegen ist das brutale crawlen möglichst kompletter
Web-Sites auch so wichtig. Schließlich sind die besten Suchtreffer nicht
immer nur in den Seiten vorhanden die Du (oder jemand anderes) bereits
besucht hast.\
Das \"nebenbei crawlen\" erzeugt nur eine Art durchsuchbare
Browsing-History aber eben keine vollständige Sicht aufs Web (okay das
geht sowieso nicht dafür ist das Web viel zu groß). Meiner Meinung nach
ist das \"nebenbei crawlen\" wichtig um den Index möglichst aktuell zu
halten und stellt ein unverzichtbares Feature dar aber es ist nur ein
Teil des Gesamtsystems \"Suchmaschine\".\
\

> <div>
>
> tinkerphone hat geschrieben:\
> Warum braucht crawlen aber so viel mehr \"power\"? Einfach weil der
> crawler viel viel schneller sites besucht als du surfen kannst.\
>
> </div>

Richtig, wobei ich bei mir (mit einem relativ dicken PC) festgestellt
habe das die Hauptbremse die Limitierung auf maximal 2 Seiten pro
Sekunde ist. Deswegen hätte ich gerne eine alternative Limitierung die
sich in Bytes pro Sekunde einstellen lässt.\
\@Orbiter:\
wäre sowas möglich? also eine alternative Limitierung in Bytes pro
Sekunde\
\

> <div>
>
> flegno hat geschrieben:\
> Ich bin im www unterwegs, erledige meine tägliche Arbeit und kann mich
> darauf verlassen \....\
>
> </div>

Das wäre bei der Lösung mit dem AddOn in gleicher Weise gegeben. Das ist
meiner persönlichen Meinung nach kein Argument für den Proxy in YaCy.\
\

> <div>
>
> flegno hat geschrieben:\
>
> > <div>
> >
> > Erik\_S hat geschrieben:Auf der anderen Seite kann ich natürlich
> > verstehen warum die Leute (und auch ich) keine Remote-Crawls
> > akzeptieren wollen, wer weiß schon was für URLs da so alles kommen
> > und auf was für Servern man damit die eigene IP-Adresse im Logfile
> > hinterlässt (vom User-Agent mal abgesehen).\
> >
> > </div>
>
> Ich muss zugeben, ich blicke hier nicht durch, ob und wie eng das
> wichtige Thema \"Crawl-Missbrauch\" mit dem \"YaCy als Proxy?\"-Thema
> verknüpft ist. Falls die Verzahnung dieser Themen kein Zwang ist, bin
> ich dafür, diese Themen getrennt, in separaten Threads zu diskutieren.
>
> </div>

Es geht darum dass das Feature \"Remote Crawls\" die Last des Crawlens
über mehrere Peers verteilen würde und damit den einzelnen Peer
entlasten könnte. Damit wäre es für viele Betreiber eines Peers
eventuell doch interessant richtige Crawl-Jobs aufzusetzen. Ohne die
Remote-Crawls wird nur der Index selber über alle Peers verteilt, mit
den Remote-Crawls wird auch die Last des Crawlens über alle Peers
verteilt, das wäre eine super Demonstration des Aspekts \"Verteilt\".
Aber leider stehen dieser technisch guten Lösung politische Probleme im
Weg, nur allein das wollte ich zum Ausdruck bringen. Das ist auf jeden
Fall kein Argument für oder gegen einen Proxy in YaCy.\
\

> <div>
>
> flegno hat geschrieben:\
> Erfahrung, Wahrnehmung mit/der Addon-Implementierung aber ist, dass
> diese wahrscheinlich wartungsintensiver\
>
> </div>

Ja, das ist wohl war. Das ist meiner Meinung nach das einzigste echte
Argument das für den Proxy und gegen AddOns spricht. Auf der anderen
Seite muss man auch klar sagen dass das Entwickeln von AddOns nicht so
extrem aufwendig ist dass das wirklich ein K.O.-Kriterium wäre. Nebst
dessen das die Implementierung eines Proxy in YaCy ebenfalls einen
gewissen Aufwand darstellt (und auch Potential für Fehler bietet wie die
403-Fehler zeigen).\
\

> <div>
>
> flegno hat geschrieben:\
> Ich bin dafür, dass die Entscheidung in der Frage \"YaCy als Proxy\"
> im Entwicklerteam, in der YaCy-Community im breiteren konzeptuellen
> Kontext betrachtet wird.\
>
> </div>

Ja, da bin ich absolut dafür.\
Es sollten aber [alle]{style="text-decoration: underline"} relevanten
Aspekte berücksichtigt werden. Dazu gehört ebenfalls die Frage welche
Lösung langfristig überhaupt einen angemessenen Nutzen bringen wird. Und
da sieht es für den Proxy im Zusammenhang mit verschlüsselten Web-Seiten
schlecht aus, dieses Problem ist nur mit einem AddOn lösbar. Darüber
hinaus sollte auch nach Nebenwirkungen der einzelnen Möglichkeiten
gefragt werden. Da hat der Proxy ebenfalls das nachsehen, er bietet mehr
potentielle Probleme wie z.B. den 403-Fehler oder unbeabsichtigte
Fehlkonfiguration die zu einem offenen öffentlichen Proxy führen (siehe
<http://forum.yacy-websuche.de/viewtopic.php?t=5411>).\
\

> <div>
>
> flegno hat geschrieben:\
> Die Proxy-Funktionalität ist in meinen Augen für ein Netzwerk
> unverzichtbar, deswegen ist es für mich selbstverständlich, dass das
> YaCy-Produkt die Proxy-Funktionalität implementiert.\
>
> </div>

Auch wenn der Proxy mit zunehmender Verschlüsselung der Web-Seiten immer
weniger Nutzwert bringt?\
Die Kosten für ein anständiges SSL-Zertifikat sinken seit Jahren
permanent und mit HTTP 2 soll Verschlüsselung zum \"Must-Have\" werden.
Als User im Internet bin ich von dieser Entwicklung sehr erfreut.
Chromium und Firefox binden bereits eine Liste von Domains ein die nur
noch verschlüsselt erreichbar sein sollen, das heist der Browser weigert
sich diese Domains ohne Verschlüsselung anzusteuern. Diese Liste ist
zwar zur Zeit noch recht überschaubar aber ich hoffe sehr dass das nicht
lange so bleibt.\
\

> <div>
>
> flegno hat geschrieben:\
> auf die Einschränkung \"YaCy ist \_nur\_ ein p2p-Netzwerk.\"
> verzichtet und als Ziel \"YaCy ist ein Netzwerk.\" anvisiert\
>
> </div>

Könntest Du das Bitte mal etwas erläutern. Ich verstehe nicht welche
\"Einschränkung\" eine
[P2P]{style="text-decoration: underline"}-Suchmaschine hat bzw. was mit
\"YaCy ist ein Netzwerk\" gemeint ist.\
\

> <div>
>
> Orbiter hat geschrieben:\
> kann man für die Auflösung der virtuellen TLD .yacy und .yacyh
> benutzen\
>
> </div>

Wenn ich das nächste UpDate meines Analyse-Tools durchführe ist das
bereits enthalten, dann werden auch die URLs /forward?hash=\.... und
/forward?name=\.... richtig funktionieren (die sind bereits in der
aktuellen Version des Tools enthalten liefern aber noch keine korrekten
IP-Adressen oder unnötige Fehler, probiers ruhig mal aus). Die
Funktionalität als richtiger HTTP-Proxy, also durch Auswertung des
Host-Feldes im HTTP-Request und durch Support für CONNECT, kommt als
nächstes.\
\
Grüße\
Erik

Statistik: Verfasst von
[Erik\_S](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9480)
--- Fr Okt 17, 2014 12:42 pm

------------------------------------------------------------------------
