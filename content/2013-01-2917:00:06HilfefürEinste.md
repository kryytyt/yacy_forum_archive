Hilfe für Einsteiger und Anwender • Re: Crawl auf Startseiten beschränken
=========================================================================

Date: 2013-01-29 17:00:06

Danke für die Antworten und das Update!
![:)](http://forum.yacy-websuche.de/images/smilies/icon_e_smile.gif "Smile")\
\
Hier ein Beispiel zur robots.txt-Situation:\
\
- In Crawl Start (Expert) folgende Url eingegeben:
<http://www.alles-wird-gut.co.at/> (Werter Betreiber bitte um Nachsicht,
dass Deine Seite hier nach dem Zufallsprinzip zu Testzwecken
herangezogen wird
![;)](http://forum.yacy-websuche.de/images/smilies/icon_e_wink.gif "Wink")
)\
- Crawl mit Standardeinstellungen durchgeführt\
- Im Creation Monitor wird 1 indizierte Seite angegeben\
- im robots.txt Monitor steht der hostname und modDate\
- die solr-Abfrage /solr/select?q=\*:\*&start=0&rows=100 ergibt 2
Ergebnisse, die Seite <http://www.alles-wird-gut.co.at/> mit
httpstatus\_i=200 sowie die Seite
<http://www.alles-wird-gut.co.at/robots.txt> mit httpstatus\_i=404

Statistik: Verfasst von
[hotel24](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=8871)
--- Di Jan 29, 2013 5:00 pm

------------------------------------------------------------------------
