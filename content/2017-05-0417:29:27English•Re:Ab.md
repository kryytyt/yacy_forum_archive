English â€¢ Re: About Yacy
========================

Date: 2017-05-04 17:29:27

> <div>
>
> luc hat geschrieben:\
> Hi bubul,\
>
> > <div>
> >
> > when adding an new website to crawl, it take sometimes more than one
> > hour for the advanced crawler load the website and show the crawler
> > monitor page\
> >
> > </div>
>
> \
> Do you also have some examples to provide for this case : it could be
> valuable when digging for future performances improvements.\
> \
>
> > <div>
> >
> > \
> > And why no option like rss to crawl sitemap every x time ?\
> >
> > </div>
>
> \
> Do you mean a Schedule option directly in the Advanced Crawler page
> (/CrawlStartExpert.html)? Because there is already the generic Process
> Scheduler page (/Table\_API\_p.html) to schedule crawls from website
> or Sitemaps. There is also the \"Scheduler and Profile editor\"
> (CrawlProfileEditor\_p.html) page dedicated to crawls scheduling.\
> \
> \<span\>One last question : did you find a way to solve your search
> performance issue mentioned \[url=\<a
> href=\"http://forum.yacy-websuche.de/viewtopic.php?f=23&t=5928\]earlier\[/url\]?\"
> class=\"smarterwiki-linkify\"\>http://forum.yacy-websuche.de/viewtopic.php?f=23&t=5928\]earlier\[/url\]?\</a\>\</span\>
>
> </div>

\
\
About crawling, it\'s all the websites in fact i add.\
\
About sitemaps, the problem is they are not listed in the scheduled
process when using the option sitemap when adding a new crawl , there\'s
only \"sitemap loader for: xxxx\" but not listed in \"recorded action\"\
\
And no, the only way i\'ve found is to send often my urls to others
peers so urls become available on network !\
\
Yacy is a very good idea but it need a new programmation, maybe in
c/c++/asm and with another database, maybe mysql or other, it need some
testing.\
\
\
And i\'ve looked at the page loaded with crawler monitor, and often it
crawl a lot of the same websites, no more of 3 or 4 websites different
for a lot of time (i\'ve many more website added to crawl with option to
crawl linked websites too\...), so i think there\'s a problem here about
how are selected urls to crawl because with only a few websites it can
have a lot of urls crawled at the same time. I\'ve seen recently it was
2000 ppm and more and in fact i don\'t know why, it was the same website
crawled each time and not a website i\'ve added, but a website
discovered when crawling the web ! There\'s a problem here with how url
are loaded and selected !

Statistik: Verfasst von
[bubul](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9712)
--- Do Mai 04, 2017 4:29 pm

------------------------------------------------------------------------
