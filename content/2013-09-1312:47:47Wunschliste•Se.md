Wunschliste • Separation Crawler/Indexer für Blacklists
=======================================================

Date: 2013-09-13 12:47:47

Beim Versuch, möglichst zielgerichtete Indexierungen zu erreichen,
stellt sich mir die Frage, ob eine Separation zwischen Crawler und
Indexer in Bezug auf die Blacklists möglich wäre.\
Eine für den Crawler erlaubte URL würde wie gehabt im Index landen. Eine
Seite, die für den Indexer verboten ist, würde zwar gecrawlt werden (d.
h. es werden neue URLs generiert), aber der Inhalt der ursprünglichen
Seite wird nicht in den Index aufgenommen.\
Das würde mMn helfen, Seiten zu finden, die selbst auf nicht
inhaltstragenden Seiten verknüpft sind, ohne dabei jedoch den Index zu
belasten.\
\
[Edit]{style="font-weight: bold"}\
Wenn ich die Terminologie richtig verstehe, ist das ganze schon beim
[Expert-Crawl]{style="font-style: italic"} manuell möglich(?) im
Abschnitt des [Document Filters]{style="font-style: italic"}
(Index-Feeder).

Statistik: Verfasst von
[surfvive](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=8791)
--- Fr Sep 13, 2013 11:47 am

------------------------------------------------------------------------
