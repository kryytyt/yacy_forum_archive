En:Debian High Availability
===========================

Date: 2013-03-07 17:16:23

[Install Redundant YaCy Applications: ]{.autocomment} configuration
replication with no downtime

← Nächstältere Version

Version vom 7. März 2013, 16:16 Uhr

(4 dazwischenliegende Versionen von einem Benutzer werden nicht
angezeigt)

Zeile 60:

Zeile 60:

 

<div>

We also do not want that the second peer does the same crawling as
configured in yacy0, therefore we also delete the api file.

</div>

 

<div>

We also do not want that the second peer does the same crawling as
configured in yacy0, therefore we also delete the api file.

</div>

 

<div>

We need this command later, therefore we create a file
\~/replicate\_all.sh with the following content:

</div>

 

<div>

We need this command later, therefore we create a file
\~/replicate\_all.sh with the following content:

</div>

−

<div>

  \~/yacy0~~/stopYACY.sh && \~/yacy1~~/stopYACY.sh

</div>

\+

<div>

  \~/yacy0/stopYACY.sh

</div>

−

<div>

  cp -R \~/yacy0/DATA \~/yacy1/~~DATA &&~~ sed
\"s/port=8090/port=8091/\" -i \~/yacy1/~~DATA~~/SETTINGS/yacy.conf
~~&&~~ rm -f \~/yacy1/~~DATA~~/WORK/api.bheap

</div>

\+

<div>

  cp -R \~/yacy0/DATA \~/yacy1/[DATA\_NEW]{.underline}

</div>

−

<div>

  \~/yacy0/startYACY.sh ~~&&~~ \~/yacy1/startYACY.sh

</div>

\+

<div>

[]{.underline} sed \"s/port=8090/port=8091/\" -i
\~/yacy1/[DATA\_NEW]{.underline}/SETTINGS/yacy.conf

</div>

−

<div>

~~This is of course only~~ a ~~tool~~ for a ~~downtime~~ replication.
~~We will see how to~~ do an ~~uptime~~ replication ~~later~~.

</div>

\+

<div>

[]{.underline} rm -f \~/yacy1/[DATA\_NEW]{.underline}/WORK/api.bheap

</div>

 

\+

<div>

  \~/yacy0/startYACY.sh

</div>

 

\+

<div>

[\~/yacy1/stopYACY.sh]{.underline}

</div>

 

\+

<div>

[rm -f \~/yacy1/DATA]{.underline}

</div>

 

\+

<div>

[mv \~/yacy1/DATA\_NEW \~/yacy1/DATA]{.underline}

</div>

 

\+

<div>

[]{.underline} \~/yacy1/startYACY.sh

</div>

 

\+

<div>

[We will install]{.underline} a [load balancer]{.underline} for [the two
peers later and because this script ensures that one of the peers runs
at any time, this is]{.underline} a [update]{.underline} replication [of
the complete peer configuration]{.underline}. [But because we
can]{.underline} do an [index-only]{.underline} replication [as well
during uptime of the peer, you should use that script only if you do a
reconfiguration of the primary peer]{.underline}.

</div>

 

 

 

<div>

We can now start both peers

</div>

 

<div>

We can now start both peers

</div>

Zeile 144:

Zeile 150:

 

<div>

and open http://{yourhost}:8100 to check that nginx is running and
successfully routes the access from 8100 to either 8090 or 8091.

</div>

 

<div>

and open http://{yourhost}:8100 to check that nginx is running and
successfully routes the access from 8100 to either 8090 or 8091.

</div>

 

<div>

You can also stop one of the yacy0 or yacy1 and the search interface at
http://{yourhost}:8100 will still be available.

</div>

 

<div>

You can also stop one of the yacy0 or yacy1 and the search interface at
http://{yourhost}:8100 will still be available.

</div>

 

\+

<div>

[]{.underline}

</div>

 

\+

<div>

[===Add a Heartbeat Check for the YaCy Peers===]{.underline}

</div>

 

\+

<div>

[There is a check-alive script which checks if a YaCy server responds on
the web interface and restarts the application if it does not respond.
This script can be called on a regular basis using a cronjob. As root,
edit /etc/crontab and add the following lines]{.underline}

</div>

 

\+

<div>

[  0 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy0/bin &&
./checkalive.sh]{.underline}

</div>

 

\+

<div>

[15 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy1/bin &&
./checkalive.sh]{.underline}

</div>

 

\+

<div>

[30 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy0/bin &&
./checkalive.sh]{.underline}

</div>

 

\+

<div>

[45 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy1/bin &&
./checkalive.sh]{.underline}

</div>

 

\+

<div>

[This will cause that twice an hour each peer is checked and restarted,
if needed. This means a maximum downtime of 15 minutes if \'\'both\'\'
peers fail.]{.underline}

</div>

 

 

 

<div>

===Test Indexing, Replication and Fail-Over Access===

</div>

 

<div>

===Test Indexing, Replication and Fail-Over Access===

</div>

Zeile 155:

Zeile 169:

 

<div>

During the replication process the index in yacy0 is first unmounted and
during this process the search inteface does not respond on search
requests. At that time the load balancer on http://{yourhost}:8100/
should switch to the second peer. When the dump is done, the index in
the second peer becomes unavailable during reading of the dump and the
load balancer should switch to the first peer again.

</div>

 

<div>

During the replication process the index in yacy0 is first unmounted and
during this process the search inteface does not respond on search
requests. At that time the load balancer on http://{yourhost}:8100/
should switch to the second peer. When the dump is done, the index in
the second peer becomes unavailable during reading of the dump and the
load balancer should switch to the first peer again.

</div>

 

 

−

<div>

===~~Add a Heartbeat Check for the YaCy Peers~~===

</div>

\+

<div>

===[Automatically do an Index Backup and Replication]{.underline}===

</div>

−

<div>

~~There is a check-alive script which checks if a YaCy server responds
on the web interface~~ and ~~restarts the application if it does not
respond. This script can be called on a regular basis using a cronjob.
As root~~, ~~edit /etc/crontab~~ and ~~add~~ the ~~following lines~~

</div>

\+

<div>

[We want to have an automated]{.underline} and [combined
backup]{.underline}, [replicate]{.underline} and [stale backup cleaning
process to ensure that]{.underline} the [replication]{.underline} peer
is [always updated to the index of the primary peer while keeping dumps
as a back-up for emergency cases]{.underline}.

</div>

−

<div>

~~10 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy0/bin &&
./checkalive.sh~~

</div>

\+

<div>

</div>

−

<div>

~~40 \* \* \* \* yacyappliance cd /home/yacyappliance/yacy1/bin &&
./checkalive.sh~~

</div>

\+

<div>

</div>

−

<div>

~~This will cause that twice an hour a~~ peer is ~~checked and
restarted, if needed~~.

</div>

\+

<div>

</div>

 

 

−

<div>

~~===Automatically do an Index Backup===~~

</div>

\+

<div>

[For this, we create a backup-directory.]{.underline} As user
yacyappliance do

</div>

−

<div>

As user yacyappliance do

</div>

\+

<div>

</div>

 

<div>

  mkdir \~/indexbackup

</div>

 

<div>

  mkdir \~/indexbackup

</div>

 

<div>

to create a storage directory for the index backup dumps. Now you can
create a backup with

</div>

 

<div>

to create a storage directory for the index backup dumps. Now you can
create a backup with

</div>

 

<div>

  mv \`\~/yacy0/bin/indexdump.sh\` \~/indexbackup/

</div>

 

<div>

  mv \`\~/yacy0/bin/indexdump.sh\` \~/indexbackup/

</div>

 

<div>

To create such a backup automatically once every day during night-time,
add the following line to /etc/crontab

</div>

 

<div>

To create such a backup automatically once every day during night-time,
add the following line to /etc/crontab

</div>

−

<div>

~~40~~ 3 \* \* \* yacyappliance cd /home/yacyappliance/ && mv
\`yacy0/bin/indexdump.sh\` indexbackup/

</div>

\+

<div>

[  5]{.underline} 3 \* \* \* yacyappliance cd /home/yacyappliance/ && mv
\`yacy0/bin/indexdump.sh\` indexbackup/

</div>

−

<div>

Then, every night a 3:~~40h~~ the index is dumped.

</div>

\+

<div>

Then, every night a 3:[05h]{.underline} the index is dumped[. This
should not take more than 25 minutes because the next checkalive ping
happens at 3:30h according to the heartbeat configuration]{.underline}.

</div>

 

 

−

<div>

~~===Add Automated Index Replication===~~

</div>

 

 

<div>

We use the index dump generated in the backup process to feed the index
dump to the replication peer yacy1.

</div>

 

<div>

We use the index dump generated in the backup process to feed the index
dump to the replication peer yacy1.

</div>

 

<div>

This is done manually by calling

</div>

 

<div>

This is done manually by calling

</div>

 

<div>

  \~/yacy1/bin/indexrestore.sh \~/indexbackup/\`ls -1tr \~/indexbackup
\| tail -1\`

</div>

 

<div>

  \~/yacy1/bin/indexrestore.sh \~/indexbackup/\`ls -1tr \~/indexbackup
\| tail -1\`

</div>

 

<div>

and automatically using the following entry in /etc/crontab

</div>

 

<div>

and automatically using the following entry in /etc/crontab

</div>

−

<div>

  ~~10 4~~ \* \* \* yacyappliance cd /home/yacyappliance/ &&
yacy1/bin/indexrestore.sh indexbackup/\`ls -1tr indexbackup \| tail -1\`

</div>

\+

<div>

  [50 3]{.underline} \* \* \* yacyappliance cd /home/yacyappliance/ &&
yacy1/bin/indexrestore.sh indexbackup/\`ls -1tr indexbackup \| tail -1\`

</div>

−

<div>

which will use the dump created ~~half an hour~~ before.

</div>

\+

<div>

which will use the dump created [45 minutes]{.underline} before[. Again
this should not take more than 25 minutes because the peer yacy1 gets
the next heartbeat ping at 4:15. Feel free to add more backup/replicate
lines to the crontab to get index backups from the primary peer to the
replication peer more frequently; i.e. add 6 hours three times to make
an backup at 3:05h, 9:05h, 15:05h and 21:05h while doing a backup to the
replication peer at 3:50h, 9:50h, 15:50h and 21:50h.]{.underline}

</div>

 

\+

<div>

 

</div>

 

\+

<div>

[Finally we need a clean-up process to removed stale backups. This can
be done with]{.underline}

</div>

 

\+

<div>

[cd \~/indexbackup && find \* -type f -mtime +7 -delete]{.underline}

</div>

 

\+

<div>

[to delete all backups which are older than seven days. To do this
automatically, put]{.underline}

</div>

 

\+

<div>

[20 4 \* \* \* yacyappliance cd /home/yacyappliance/indexbackup && find
\* -type f -mtime +7 -delete]{.underline}

</div>

 

\+

<div>

[into the crontab. This will delete the update ten minutes after the
replication happened.]{.underline}

</div>

 

\+

<div>

[Please modify the crontab lines if you wish to do backup and
replication more/less often]{.underline}.

</div>

 

 

 

<div>

===Automatically Update to Latest Code Changes===

</div>

 

<div>

===Automatically Update to Latest Code Changes===

</div>

Zeile 184:

Zeile 200:

 

<div>

  ../../yacy0/stopYACY.sh && tar xfz \`ls -1tr \| tail -1\` -C
../../yacy0 \--strip-components=1 && ../../yacy0/startYACY.sh

</div>

 

<div>

  ../../yacy0/stopYACY.sh && tar xfz \`ls -1tr \| tail -1\` -C
../../yacy0 \--strip-components=1 && ../../yacy0/startYACY.sh

</div>

 

<div>

  ../../yacy1/stopYACY.sh && tar xfz \`ls -1tr \| tail -1\` -C
../../yacy1 \--strip-components=1 && ../../yacy1/startYACY.sh

</div>

 

<div>

  ../../yacy1/stopYACY.sh && tar xfz \`ls -1tr \| tail -1\` -C
../../yacy1 \--strip-components=1 && ../../yacy1/startYACY.sh

</div>

−

<div>

We can run this also automatically in ~~three steps in~~ the
/etc/crontab, add the following lines:

</div>

\+

<div>

We can run this also automatically[, twice a day]{.underline} in [a 12
hour distance by alternating the peers to prevent that a bad release
destroys both peers at]{.underline} the [same time. In]{.underline}
/etc/crontab, add the following lines:

</div>

−

<div>

  ~~20~~ 4 \* \* \* yacyappliance cd /home/yacyappliance/yacy\_deploy &&
git pull \--tags origin master && ant clean all dist

</div>

\+

<div>

  [30]{.underline} 4 \* \* \* yacyappliance cd
/home/yacyappliance/yacy\_deploy && git pull \--tags origin master &&
ant clean all dist

</div>

 

<div>

  40 4 \* \* \* yacyappliance cd
/home/yacyappliance/yacy\_deploy/RELEASE && ../../yacy0/stopYACY.sh &&
tar xfz \`ls -1tr \| tail -1\` -C ../../yacy0 \--strip-components=1 &&
../../yacy0/startYACY.sh

</div>

 

<div>

  40 4 \* \* \* yacyappliance cd
/home/yacyappliance/yacy\_deploy/RELEASE && ../../yacy0/stopYACY.sh &&
tar xfz \`ls -1tr \| tail -1\` -C ../../yacy0 \--strip-components=1 &&
../../yacy0/startYACY.sh

</div>

−

<div>

  ~~10 5~~ \* \* \* yacyappliance cd
/home/yacyappliance/yacy\_deploy/RELEASE && ../../yacy1/stopYACY.sh &&
tar xfz \`ls -1tr \| tail -1\` -C ../../yacy1 \--strip-components=1 &&
../../yacy1/startYACY.sh

</div>

\+

<div>

  [15 18 \* \* \* yacyappliance cd /home/yacyappliance/yacy\_deploy &&
git pull \--tags origin master && ant clean all dist]{.underline}

</div>

 

\+

<div>

[25 18]{.underline} \* \* \* yacyappliance cd
/home/yacyappliance/yacy\_deploy/RELEASE && ../../yacy1/stopYACY.sh &&
tar xfz \`ls -1tr \| tail -1\` -C ../../yacy1 \--strip-components=1 &&
../../yacy1/startYACY.sh

</div>

 

\+

<div>

[Finally we should clean up the generated releases the same way as we
delete old backup files. This can be done with]{.underline}

</div>

 

\+

<div>

[cd \~/yacy\_deploy/RELEASE && find \* -type f -mtime +7
-delete]{.underline}

</div>

 

\+

<div>

[and as a cron job with]{.underline}

</div>

 

\+

<div>

[20 8 \* \* \* cd /home/yacyappliance/yacy\_deploy/RELEASE && find \*
-type f -mtime +7 -delete]{.underline}

</div>

 

 

 

<div>

===Usage of this High Availability Configuration===

</div>

 

<div>

===Usage of this High Availability Configuration===

</div>
