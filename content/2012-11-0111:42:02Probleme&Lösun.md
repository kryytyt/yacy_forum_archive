Probleme & Lösungen • Re: Crawler beschleunigen
===============================================

Date: 2012-11-01 11:42:02

tja da krame ich mal den alten Topic wieder raus..\
(nicht nur) aufgrund eines Kunden habe ich den Crawler die letzten Tage
schwer überarbeitet. Der Algorithmus ist nun so:\
- lade (bis zu 100000) URLs aus dem Stack und sortiere sie in
domain-Listen\
- von den Domain-Listen mache eine Prognose welche Domains man ohne
Bremse laden darf und lege je eine URL in eine -\> zero-waiting Liste\
- von der zero-waiting-Liste nehme nur ein drittel welches die meisten
URLs haben (dadurch entladen sich die großen Listen früher ohne warten
zu müssen)\
- die zero-waiting-Liste wird persistiert und geleert\
- wenn keine zero-waiting-Liste da ist bzw. nicht gefüllt werden kann,
nehme die URL mit der besten Warteprognose.\
\
Warteprognose heisst hier: wie lange muss man warten wenn man weiss was
in der Robots.txt steht, ohne dass man die geladen hat.\
In der Vergangenheit war diese Prognose oft falsch, weil es einige Hosts
mit hohen crawl-delays gibt. Die haben dann alles versaut. Jetzt wird
daher nebenläufig jede robots.txt geladen, sobald man weiss das man die
mal brauchen kann, und die Warteprognose kann daher die robots.txt mit
berücksichtigen, was das ganze schneller machen sollte\...

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Do Nov 01, 2012 11:42 am

------------------------------------------------------------------------
