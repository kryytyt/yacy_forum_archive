English â€¢ Re: PPM limitations in YaCy?
======================================

Date: 2014-11-12 19:51:18

> <div>
>
> Orbiter hat geschrieben:\
> There is actually a hardcoded limitation to 2 documents per second for
> the same domain. This is done in connection with a proper
> identification of the crawler as \'yacybot\'. The combination of the
> limitation and the identification of the crawler is promise to web
> hosters that YaCy is a good behaving robot and does not overload web
> services.\
>
> </div>

\
\
So I\'ve thought.\
\
Tried to crawl a local site that\'s quiet big with the current speed -
around 120 PPM. After a few days of crawling my system crashed, which
screwed the crawl. For some reason it was gone on next run of YaCy, so
it never finished.\
I want to increase the speed a little - say 4. The server certainly can
handle more than 5-6 pages, so it will be no problem.\
\
Also I wonder what will happen if there is a robots.txt and it allows
more than the hardcoded value?\
Will YaCy adjust to the limit that robots.txt is allowing to or will it
stick to the hardcoded value?\
\
Thanks for the quick response!

Statistik: Verfasst von
[sbolokanov](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9501)
--- Mi Nov 12, 2014 7:51 pm

------------------------------------------------------------------------
