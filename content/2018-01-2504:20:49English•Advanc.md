English â€¢ Advanced crawler: \"FINAL\_LOAD\_CONTEXT post url not allowed\"
=========================================================================

Date: 2018-01-25 04:20:49

I\'ve been using YaCy as the intranet search at my office, and it\'s
mostly been working quite well, but I noticed recently that YaCy is
failing to parse a set of pages, all with the same rejection reason:\
\

> <div>
>
> \
> FINAL\_LOAD\_CONTEXT post url not allowed\
>
> </div>

\
\
All the pages are basically in the format
\"http://www.office.internal/bugs/bug.php?number\" (it\'s a read-only
web interface I wrote for Fogbugz, the old bugtracker we use at the
office, which came in handy since YaCy can\'t log in and parse the
\'actual\' bugtracker).\
\
If I just use the simple crawler, it seems to work fine. So there\'s
presumably some setting in the Advanced Crawler (which I used to
configure all of the repeatedly scheduled jobs) that\'s preventing this,
but I can\'t seem to figure out which, and this is making it hard for me
to set up a targeted job to be repeated.\
\
Also, an odd note, for some reason (both in the actually-crawled pages
and in the list of rejections when I try to use the Advanced Crawler),
all the URLs have \"=\" appended to them. I\'m quite confused as to
where that\'s coming from, since none of the links it\'s following for
those pages include an equals sign.

Statistik: Verfasst von
[keithzg](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9815)
--- Do Jan 25, 2018 4:20 am

------------------------------------------------------------------------
