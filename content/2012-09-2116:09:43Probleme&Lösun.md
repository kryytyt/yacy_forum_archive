Probleme & Lösungen • Re: Lokaler Crawler läuft Amok
====================================================

Date: 2012-09-21 16:09:43

also es stimmt, der crawler hatte völlig die Begrenzung verloren für
alle Crawls die nicht über den normalen Start gestartet wurde, und zwar
durch einen falschen Default-Wert eines neuen Parameters, den \'no depth
limit pattern\'. Der stand auf catchall und soll aber catchnever sein.
Hab einen Patch im git.\
\
Dieser neue \'no depth limit pattern\' kann man neben dem Crawl start
eingeben und hebt, wenn er mit der URL matcht, die depth auf. Das kann
man dazu nutzen um so zu crawlen dass man irgenwohin kommt wo der Pfad
passt um dort dann so lange durchzucrawlen um alles in dem Pfad ist
reinzulesen. Wenn dieses regex pattern dann catchall ist, hört das
natürlich nicht mehr auf.

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Fr Sep 21, 2012 3:09 pm

------------------------------------------------------------------------
