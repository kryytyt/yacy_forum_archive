Presse • Re: Schlechte Erfahrungen mit dem Yacy-Bot?
====================================================

Date: 2013-10-14 01:39:27

ohne Trollfutter verstreuen zu wollen: der yacybot ist äusserst
konservativ was die robots.txt angeht! Das heisst:\
\
- die robots.txt wird selbstverständlich befolgt\
- der crawler läd niemals mehr als 2 Seiten pro Sekunde von der gleichen
Domäne um eben nicht zu DoSen,\
- der crawlen ist gar nicht unbekümmert weil er auch noch die
Antwortzeit des remote Servers misst und mindestens das doppelte der
letzten Antwortzeit als mindest-Wartezeit zwischen zwei Ladezugriffen
nutzt. Eine Einsicht in die Statistik über die remote response Time hat
man in jedem Peer in /api/latency\_p.xml\
\
Um das plausibel zu machen:\
- bei jeden Crawl Start wird die robots.txt geladen. Nur wenn diese das
Crawlen erlaubt, wird auch der Crawl Start erlaubt. Das sieht man
interaktiv während man die Start-URL eintippt durch Erscheinen des
grünen Hakens.\
- eine Einsicht in die Liste der geladenen robots.txt erhält man über
die Seite /Tables\_p.html?table=robots\
- einen Test, ob die robots.txt erkannt und richtig verstanden wird kann
man mit Hilfe der Seite /CrawlCheck\_p.html durchführen.\
\
Ausserdem gibt der User-Agent von YaCy den Link
<http://yacy.net/bot.html> an, welcher erklärt dass Yacy die robots.txt
befolgt.

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Mo Okt 14, 2013 12:39 am

------------------------------------------------------------------------
