Hilfe für Einsteiger und Anwender • Re: Crawling limit fuer eigenen Server aufheben
===================================================================================

Date: 2017-01-03 12:12:38

> <div>
>
> sixcooler hat geschrieben:\
> Hallo darkfader,\
> \
> man kann sich eine robots.txt schreiben in der man ein zügigeres
> crawlen gestattet - siehe : [PPM limitations in
> YaCy?](http://forum.yacy-websuche.de/viewtopic.php?f=23&t=5444&p=31286&hilit=robots.txt#p31282){.postlink}\
> \
> cu, sixcooler.\
>
> </div>

\
\
Vielen Dank, ich werd\'s probieren!\
(Der robots-wait wird aber immer mit 0ms angezeigt. Aber versuchen
kostet schliesslich nix
![:-)](http://forum.yacy-websuche.de/images/smilies/icon_e_smile.gif "Smile")

Statistik: Verfasst von
[darkfader](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9724)
--- Di Jan 03, 2017 12:12 pm

------------------------------------------------------------------------
