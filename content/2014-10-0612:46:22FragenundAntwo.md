Fragen und Antworten • Re: YaCy als Proxy?
==========================================

Date: 2014-10-06 12:46:22

Hallo,\
\
ich persönlich möchte mich dafür aussprechen das Proxy-Feature aus YaCy
zu entfernen, aus folgenden Gründen:\
Dieses Feature macht den HTTP-Server in YaCy komplexer da dieser für
jeden Zugriff entscheiden muss ob der Zugriff den YaCy-Peer selber
betrifft oder per Proxy weitergeleitet werden soll. Ein einfaches und
simples Design fördert auch immer die Sicherheit und die Fehlerarmut des
Systems und ist somit ein Vorteil für die User. Das selbe trifft auch
auf den Crawler ansich zu der dann nur noch Seiten analysieren muss die
er selber unter kontrollierten Bedingungen geholt hat und keine
\"vorbeifliegenden\" Daten mehr Crawlen muss.\
Das \"nebenbei-crawlen\" geht auch anders, es gibt ein Browser-AddOn das
alle aufgerufenen URLs parallel an einen (beliebigen) konfigurierten
YaCy-Peer weiterreicht und damit den dortigen Crawler quasi mit
einzelnen URLs füttert. Für das \"nebenbei-crawlen\" muss eh eine
Modifikation am Browser vorgenommen werden, ob nun einen Proxy zu
konfigurieren oder ein AddOn zu installieren ist kein großer
Unterschied. Dafür kann das AddOn eventuell besser auf die Privatsphäre
des Users achten, es könnte z.B. im \"Privat-Modus\" (den heutzutage
alle Browser unterstützen) inaktiv bleiben.\
Per HTTPS verschlüsselte Seiten sind per Proxy gar nicht crawlbar aber
wenn YaCy einfach nur die URL gegeben wird kann der Crawler selber eine
verschlüsselte Verbindung zum Web-Server aufbauen. In HTTP 2 soll
Verschlüsselung zur Pflicht werden, Chromium wird per HTTP 2 wohl gar
keine unverschlüsselten Verbindungen mehr aufbauen können und in Firefox
ist das nur versteckt erreichbar. Der Nutzwert eines Proxy-Crawlers
könnte also demnächst gen Null sinken.\
\
Das einzigste Feature das wirklich aus YaCy verschwinden würde wäre der
einfache Zugriff auf die beiden Top-Level-Domains .yacy und .yacyh aber
dafür habe ich eine Lösung die sich kurz vor den Startlöchern befindet.\
\

> <div>
>
> TmoWizard hat geschrieben:\
> Eine einfache Webseite kann immerhin mehrere Stunden brauchen, bis der
> Crawler fertig ist.\
>
> </div>

Oder auch mal Tage, für wireshark.org hat mein Peer mehrere Tage
gebraucht und das trotz dickem PC und schneller Internetanbindung. Wobei
ich da eher der Meinung bin das die Limitierung auf 2 Zugriffe pro
Sekunde das Problem darstellt aber hier gilt es natürlich abzuwägen wie
viel Leistung der eigene PC als Crawler erübrigen kann und ob die
gecrawlte Web-Seite durch zu intensives crawlen eventuell geDOSt wird.
Ich würde mir hier lieber eine Limitierung in Bytes pro Sekunde wünschen
damit meine Internetanbindung nicht überlastet wird selbst wenn der PC
auf dem YaCy läuft über ausreichend CPU-Power verfügt. Da es keinen Weg
gibt einer TCP-Verbindung eine Priorität mitzugeben, die z.B. der
Heim-Router beachten könnte damit andere PCs im heimischen Netz nicht
ausgebremst werden, ist ein festes Bandbreiten-Limit die einzigst
machbare Lösung.\
\
Gerade wegen dem langsamen Crawlen durch nur einen Crawler gibt es ja
das Feature die Crawl-Last auf mehrere Peers zu verteilen aber kaum
einer hat in seinem Peer das Akzeptieren von Remote-Crawls aktiviert
also bleibt dieser Vorteil einer
[verteilten]{style="text-decoration: underline"} Suchmaschine leider
ziemlich ungenutzt. Auf der anderen Seite kann ich natürlich verstehen
warum die Leute (und auch ich) keine Remote-Crawls akzeptieren wollen,
wer weiß schon was für URLs da so alles kommen und auf was für Servern
man damit die eigene IP-Adresse im Logfile hinterlässt (vom User-Agent
mal abgesehen). Das Risiko früh um 6 Uhr eine unangemeldete
Hausdurchsuchung mit Beschlagnahmung aller Computer (seine Computer
sieht man mit hoher Wahrscheinlichkeit nie oder erst nach vielen Jahren
wieder selbst wenn man nachweislich unschuldig ist) usw. zu bekommen
will ganz sicher niemand freiwillig eingehen. Da solche Dinge in
Deutschland leider schon öfters vorgekommen sind ist das kein rein
fiktives Risiko sondern eine ernstzunehmende Gefahr. Hier leidet also
eine technische Lösung unter einem politischen Problem.\
\

> <div>
>
> flegno hat geschrieben:\
> einfach nebenbei eine Art erweiterte Lesezeichen-Sammlung (meine Sicht
> auf den YaCy-Index) generieren\
>
> </div>

Ich sehe das genauso, gerade das \"nebenbei-crawlen\" zeigt doch der
Suchmaschine meines Vertrauens wofür ich mich wirklich interessiere und
baut somit einen (für mich) maximal nützlichen Index auf.\
\
Ich bin dafür dass das Proxy-Feature aus YaCy verschwindet, damit wären
auch die HTTP-403-Fehler vorbei, und dafür die Möglichkeiten zum
\"nebenbei-crawlen\" per Browser-AddOn zu verbessern. Für letzteres
würde ich eventuell Geld ausgeben.\
\
Grüße\
Erik

Statistik: Verfasst von
[Erik\_S](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9480)
--- Mo Okt 06, 2014 11:46 am

------------------------------------------------------------------------
