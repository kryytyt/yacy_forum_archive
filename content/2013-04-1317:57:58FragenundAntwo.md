Fragen und Antworten â€¢ Re: 1.4 ranking problem
==============================================

Date: 2013-04-13 17:57:58

ok, this needs a bit of explanation: the new fields must be filled with
a web crawl to make it functional, and the formula as given above is
purely experimental. It considers the number of external links to a web
pages and the number of different external domains as important and
increases the ranking further if the web page has a low click depth. All
values which appear in the forumla are computed in a two-pass process:\
\
- first the documents are indexed and a web structure index is generated
in parallel. The references and clickdepth values are filled with dummy
values and the document gets also a \'ready for postprocessing\' flag.\
- when all crawls are finished, a postprocessing step is performed: all
documents with the postprocessing flag are then filled with the actual
values after a clickdepth computation and a reference count. This can
only be done after all crawls because only then the information is
present.\
\
That means right after the crawl is finished the ranking formula using
this values will not work, you must wait additionally until the
postprocessing is finished. This can currently only be monitored in the
log, not in the web interface. However, this process is pretty fast.\
\
The counting of external references and the clickdepth can be consideres
as something like a \'poor mans citation rank\' which can be the basis
for a page-rank-like second postprocessing step. Before the development
for this can start we need more experience with the current formula.\
\
[Please do your own experiments with the formula and give a feed-back
for enhancements here!]{style="font-weight: bold"}

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Sa Apr 13, 2013 4:57 pm

------------------------------------------------------------------------
