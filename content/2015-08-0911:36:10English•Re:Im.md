English â€¢ Re: Improving ranking using neural networks and genetic algo
======================================================================

Date: 2015-08-09 11:36:10

> <div>
>
> Cajun hat geschrieben:\
> Hi biolizard89\
> \
> \
> I think, your concept of distributing ranking-algorithms, rather than
> exchanging data itselves (with all their privacy- and spam- concerns),
> might open a new door to look for alternative types of solutions
> aiming for the improvement of ranking-algorithms \...
> ![:?](http://forum.yacy-websuche.de/images/smilies/icon_e_confused.gif "Confused")\
> \
> \
> Trying to bring things, thoughts, knowledge and discussion together:\
> \
> A fully centralized approach is the domain of commercial SE\'s. It
> doesn\'t care much of privacy, but it supports best BIG-DATA anylytics
> in order to develop \'most-optimal\' rankings in terms of customer
> satisfaction and commercial interests.\
> \
> A \'cooperative approach\' relying on centralized data, resulted in a
> crucial loss of privacy - or, in an increased risk of getting spammed
> and tampered with disinforming data, respectively. Obviously, we
> don\'t see any great solutions coming for that.\
> \
> A \'cooperative approach\', based on social graphs and using a
> restricted data exchange, might bring most of needs for privacy and
> data-secuity into balance. However, it is yet to be operationalized
> fully.\
> \
> A pure algorithmic approach - this idea came up for me, when thinking
> about your concept of exchanging algorhithms - could provide all
> intelligence locally. It would not be restricted to influence
> processes at query-time, but it also might influence an (local?)
> index, by trying to avoid fetching and indexing false-positive hits.
> Ranking algoritms might be choosen explicitely by the user, or elected
> (or even trained) by the local search- & find- history. In such a
> scenario, the development focus shifted towards the competition of
> exchangeable \'intelligent\' algorithm plugins - avoiding to get stuck
> with ambiguities of clustering, disinformation, and privacy, which can
> be considered typical side-effects of centralized data-store
> analytics.\
> \
> The approaches mentioned last, might make use of YaCy\'s query-log,
> and be realized on the browser\'s side by \"Greasemonkey\" (or sthg.
> similar, however, restricting it\'s use to firefox and chrome by now),
> and on some logic preserved by the server.\
> \
> \
> Did you miss some relevant views/issues/points within this try of a
> review?\
> \
> \
> Best Regards\
>
> </div>

\
\
This is an accurate summary, I think. Two additional things that I think
are noteworthy.\
\
(1) A somewhat large data set is necessary to avoid fitting the ranking
algorithm to noise rather than signal (called \"overfitting\" in machine
learning). If you have a small number of searches to train against, or a
large number that are all similar in some (potentially non-obvious) way,
then the algorithm you end up with is unlikely to perform well against
different searches. In my initial experiment, I trained against the top
100 results from 300 Google searches (selected at random from the AOL
dataset), using a genetic algorithm. The genetic algorithm took about 6
generations before it started overfitting. Changing various parameters
of the genetic algorithm might improve this, but I suspect a larger
sample size of training data would also be helpful. (To be fair, before
it started overfitting, it had closed about a quarter of the gap between
YaCy and DuckDuckGo, so it was still quite good for a first attempt.)\
\
(2) However, the large data set doesn\'t have to be all on one user\'s
computer. Based on a (relatively contrived) simulation I did where I
divided the dataset into 8 parts, put each one on a separate node, and
had the nodes exchange a linear combination of fitness values according
to a simulated social graph, the genetic algorithm reached nearly the
same fitness as the single-user version. It took about 4 times as many
generations to do so, although the number of runs was small enough and
the simulated social graph contrived enough that it\'s not at all clear
whether a 4-fold increase will be representative of other cases. Even
so, 4-fold increase in number of generations isn\'t a bad tradeoff for
the better sample size and better privacy you get by exchanging only
fitness values over a social graph.\
\
Another thing that could be done on the single-user side, maybe, is some
kind of custom link graph weighting based on the user\'s browsing
habits. It\'s not particularly hard for a Greasemonkey script to keep
track of which web pages a user visits, and that data could be combined
with YaCy\'s link graph to estimate the user\'s likely interest in
results. For example, a search result which has a large number of degree
2 or 3 link graph paths from domains that you visit, may be inferred to
be more relevant to you than one that only has a small number of degree
5 or 6 link graph paths from domains that you visit. Graph theory is not
really my thing, so I\'m not sure how well this would work, but I think
it\'s a logical extension of how Google does some of its ranking. I
might play around with it later to see how well it ends up working.

Statistik: Verfasst von
[biolizard89](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=8861)
--- So Aug 09, 2015 10:36 am

------------------------------------------------------------------------
