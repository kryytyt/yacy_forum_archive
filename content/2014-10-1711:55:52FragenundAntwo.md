Fragen und Antworten • Re: YaCy als Proxy?
==========================================

Date: 2014-10-17 11:55:52

Guten Morgen zusammen!\
\
Von was für einem Add-on ist da die Rede? Für welchen Browser bitte und
für welches System? Was soll das Add-on bezwecken? Schon mal bedacht,
daß auch gar nicht jeder Browser Add-ons verwenden kann?\
\
Hier muß bedacht werden, daß nicht alle das Gleiche verwenden. Ich z. B.
arbeite hier mit Linux/Kubuntu und mein Browser ist SeaMonkey! Es wäre
bei einem Add-on für Firefox also möglich, daß es bei mir auch läuft.
Doch wie sieht das aus bei Chrome, Safari, Internet Explorer, Midori,
Konqueror und all den anderen Browsern, die es noch so gibt?\
\
Ich glaube kaum, daß jemand wegen YaCy den Browser wechseln wird! Ein
Add-on würde nur bedeuten, daß es für die Programmiere mehr Aufwand ist
und für die Nutzer noch ein Ding, um dessen Updates sie sich kümmern
müßten. Wenn ich mir dann in meinen obigen Links die verschiedenen
Versionsnummern der von YaCy so betrachte wird mir klar, daß den Leuten
ihre Sicherheit egal ist!\
\

> <div>
>
> Erik\_S hat geschrieben:\
> Auf der anderen Seite kann ich natürlich verstehen warum die Leute
> (und auch ich) keine Remote-Crawls akzeptieren wollen, wer weiß schon
> was für URLs da so alles kommen und auf was für Servern man damit die
> eigene IP-Adresse im Logfile hinterlässt (vom User-Agent mal
> abgesehen).\
>
> </div>

\
\
[[Du hast mit diesem einen einzigen Satz den Crawler als für dich nicht
brauchbar erklärt, obwohl du für den Crawler
bist!]{style="font-style: italic"}]{style="font-weight: bold"}\
\
Welche Suchtiefe hast du denn bei deinem Crawler eingestellt?
[[1]{style="font-style: italic"}]{style="font-weight: bold"} oder was?
Dann kannst du gleich den Proxy verwenden. Spätestens aber einer Tiefe
von [[3]{style="font-style: italic"}]{style="font-weight: bold"} kannst
du nicht mehr kontrollieren, was in deinem Index landet:\
\

1.  die zu crawlende Website
2.  Die dort verlinkten Websites
3.  Die verlinkten Sites auf den verlinkten Sites

\
Das ist wie ein Schneeballsystem:\
\
Gehen wir mal von
[[10]{style="font-style: italic"}]{style="font-weight: bold"} Links pro
Site aus, das läßt sich noch relativ überschaubar berechnen:\
\
Die erste Site hat also
[[10]{style="font-style: italic"}]{style="font-weight: bold"} Links, die
nächsten [[10]{style="font-style: italic"}]{style="font-weight: bold"}
Websites wären dann schon
[[10\*10]{style="font-style: italic"}]{style="font-weight: bold"} Links,
also [[100]{style="font-style: italic"}]{style="font-weight: bold"}
Sites. Diese
[[100]{style="font-style: italic"}]{style="font-weight: bold"} Sites
sind dann schon
[[100\*10]{style="font-style: italic"}]{style="font-weight: bold"}
Links, also
[[1.000]{style="font-style: italic"}]{style="font-weight: bold"} Sites!
Weißt Du etwa, was dort alles oben ist?\
\
Nun ist es aber so, daß kaum eine Site nur
[[10]{style="font-style: italic"}]{style="font-weight: bold"} Links
enthält. Ich habe selbst einige Artikel mit
[[20]{style="font-style: italic"}]{style="font-weight: bold"} und mehr
Links geschrieben, da kommst Du beim Crawlen mit einer Tiefe von
[[3]{style="font-style: italic"}]{style="font-weight: bold"} schnell mal
so auf [[50.000]{style="font-style: italic"}]{style="font-weight: bold"}
und mehr Seiten! Kannst Du mir sagen, was dort alles auf diesen
Servern/Websites ist? Mein Index geht wie schon geschrieben langsam in
Richtung [[11]{style="font-style: italic"}]{style="font-weight: bold"}
Millionen Dokumente, von denen ich wohl nur einen geringen Bruchteil je
gesehen habe. Mit dem Proxy alleine hätte ich das natürlich nicht
geschafft, aber es waren bisher nur
[[3]{style="font-style: italic"}]{style="font-weight: bold"} Crawler
daran beteiligt!\
\
Wenn ich sämtliche Sites, die ich seit der Installation von YaCy besucht
habe gecrawlt hätte, dann wäre ich jetzt bei den \"Active Principal\"
wohl einsam an erster Stelle, die derzeit dort stehenden
[[75,8]{style="font-style: italic"}]{style="font-weight: bold"}
Millionen Links/Dokumente schaffe ich locker bei einer Suchtiefe von
[[3]{style="font-style: italic"}]{style="font-weight: bold"}!\
\
Ich bin ab Ende nächster Woche für ein paar Tage außer Haus, dann kann
ich ja spaßeshalber mal einen Crawler mit der Suchtiefe
[[5]{style="font-style: italic"}]{style="font-weight: bold"} \"nur\" auf
meine eigentliche Homepage [(nicht das
Blog!)]{style="font-style: italic"} loslassen. Dann wird nicht nur mein
Blog inklusive neuer Kommentare und Artikel neu indexiert, da kommen
dann auch ein paar Verlage [(Heise, Golem, Spiegel, Zeit,
Welt\...)]{style="font-style: italic"}, die Wikipedia, Blogs und was
weiß ich noch alles dazu!\
\
Du weißt also nicht, welche URLs da so kommen als \"Active Principal and
Senior Peer\"? Na und? Das weißt Du jetzt mit deinem eigenen Crawler
garantiert auch nicht, das geht nämlich
[[nur]{style="font-style: italic"}]{style="font-weight: bold"} mit dem
Proxy und den direkt von dir besuchten Sites bei kleinstmöglicher
Suchtiefe! Dein Index wird dann allerdings nicht sonderlich groß werden,
denn besonders viele Sites wirst du ja auch nicht ansurfen.\
\
Ich bin [[nicht]{style="font-style: italic"}]{style="font-weight: bold"}
gegen den Crawler, der erfüllt schon seinen Sinn und Zweck und ich
verwende ihn ja auch immer mal wieder. Für einen normalen Anwender ist
der Proxy allerdings die einfachere und bessere Wahl, vor allem dann,
wenn man wie Du nicht jeden möglichen Unsinn im eigenen Index haben
will! Der eigene Crawler eignet sich nur dann, wenn man so viele
Websites/Dokumente wie möglich indexieren will.

Statistik: Verfasst von
[TmoWizard](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9448)
--- Fr Okt 17, 2014 10:55 am

------------------------------------------------------------------------
