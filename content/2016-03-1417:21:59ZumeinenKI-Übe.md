Zu meinen KI-Überlegungen kamen ein paar interessante \...
==========================================================

Date: 2016-03-14 17:21:59

Zu meinen KI-Überlegungen kamen ein paar interessante Kommentare rein.
Erstens haben mir gleich mehrere Einsender die dicke Kröte zu schlucken
gegeben, dass meine Befürchtungen zum Gesundheitssystem schon längst
eingetroffen sind:

> Ich kann dir als Pharmaziestudent sagen, dass bereits heute JEDES
> MEDIKAMENT (!!!) von KI in gewissem Maße gemacht wird.
>
> \"Drug Design\" bzw. die Suche nach Wirkstoffen funktioniert nämlich
> folgendermaßen:
>
> Zunächst sucht man den Liganden, der an den gewünschten Rezeptor
> bindet. Da es unglaublich viele Moleküle gibt, muss zunächst am
> Computer vorausgewählt werden. Diese Programme werden von
> Bioinformatikern geschrieben, die ausschließlich KI benutzen. Woher
> ich das weiß? 90% der Programme sind zwar closed source (gehören der
> Pharmaindustrie), aber die, die es an der Uni gibt, nutzen neuronale
> Netze (<http://www.mrupp.info/publications.html>). Erst nachdem es die
> ersten \"hits\" gibt bzw. man eine Leitstruktur ausgesucht hat, wird
> mit rationaleren Methoden weitergearbeitet (z.b. [unser
> Programm\"](http://vammpire.pharmchem.uni-frankfurt.de/)). Dies ist
> aber eigentlich auch nicht so toll, weil z.B.
> [QSAR](https://en.m.wikipedia.org/wiki/Quantitative_structure%E2%80%93activity_relationship)
> davon ausgeht, dass wenn wir gleiche Molekülteile haben, diese stets
> ähnliche Wirkung haben. Dies führt zum \"QSAR paradox\", das den
> Sachverhalt beschreibt, dass die Grundannahme nicht stimmt (Contergan!
> Nein! Doch! Oh!).
>
> Ich denke, dass es hier eine große Marktlücke gibt. Die guten
> Chemiker, die auch Ahnung von Quantenmechanik haben, arbeiten an
> Programmen, die kleine Moleküle sehr gut beschreiben/ Eigenschaften
> vorhersagen.
>
> Die \"schlechteren\" arbeiten u.a. bei uns in der Synthese und
> konkurrieren leicht mit den Pharmazeuten.
>
> Die Biophysiker beschäftigen sich mit spektroskopischen Methoden von
> Biomolekülen. Dies erfolgt rational und es werden auch Fortschritte
> erzielt.
>
> Die Bioinformatiker sind die einzigen, die sich mit Computermodellen
> von Proteinen usw. befassen, greifen aber fast ausschließlich auf
> machine learning zurück. Ich kenne nur eine Ausnahme:
> <http://www.merzgroup.org/>

Hier noch ein Einsender, der in eine ähnliche Bresche schlägt:

> a couple of thoughts of mine about Google\'s KI: you did mention
> neural networks and related things. In medicinal chemistry people have
> been classifying chemical compounds for 30 years (!) using neural
> networks. It works extremely well - this one is toxic, that one
> isn\'t, this is a Glycoprotein P substrate, that one is not - even in
> prospective studies. It\'s impossible to derive any rules from all of
> these studies but my thought has always been: if it were simple they
> wouldn\'t have to resort to neural networks.
>
> You also mentioned healthcare. People are slowly waking up to the
> realities of systems biology. It really isn\'t that there are
> metabolic cycles or feedback loops, biologial reality doesn\'t look
> like this at all. What really happens is that there are all sorts of
> interacting networks of things, some of which may compensate for
> others. This is how evolution works, after all, though gene
> duplication and repurposing of enzymes. The whole fabric is already
> impossible to understand for any human and cannot be turned into a
> simple model. Hence the very expensive realities of pharmaceutical
> R&D. There was no reason to expect that COX-2 inhibitors would put
> those that take it at risk of heart disease, but it is a fact that
> they do. No idea why.

Dann gab es noch einen schönen Kommentar aus der Sci-Fi-Ecke:

> Du sagst im Grunde, dass der Mensch die höchste Intelligenz auf diesem
> Planeten war und ist, und folgerst, dass er es selbstverständlich auch
> bleiben sollte. Wir Menschen verwenden einen Gutteil unserer
> Ressourcen darauf uns zu reproduzieren und das beste aus unserem
> Nachwuchs zu machen. Wenn wir nun plötzlich in der Lage sind ein
> System zu erschaffen, das uns intellektuell überflügelt, dann sollten
> wir vielleicht aufhören uns zu reproduzieren und unsere Ressourcen in
> die Entwicklung dieses \"besseren\" Systems stecken. Für mich klingt
> das nach dem logisch nächsten Schritt in der Evolution. Das Thema ist
> nur hochgradig angstbesetzt.

und weiter (war eine sehr lange Zuschrift, ich gebe daher aus
Platzgründen nur Teile wieder):

> In der KI-Forschung ist die Frage der Vorhersagbarkeit solcher Systeme
> (beider Varianten) natürlich schon ausgiebigst diskutiert worden. Das
> Ergebnis ist ein interessantes Paper namens \"Structural Risk
> Minimization\", das besagt: Je mehr (Lern)Kapazität ein Modell hat,
> desto höher ist das Risiko, dass es \"was falsches\" lernt, also einen
> Generalisierungsfehler macht. Und umgekehrt: Je mehr
> \"widersprüchliche\" Daten von einem lernenden System korrekt gelernt
> werden können sollen, desto höher ist die benötigte Kapazität.
>
> Für diese Kapazität gibt es auch ein Maß, und zwar die sog.
> VC-Dimension. Die VC-Dimension ist genau die maximale Anzahl an
> Datenpunkte, für ein Lerner - unabhängig von der Färbung der
> Datenpunkte - ein Modell (Programm) ausspuckt, das diese Punkte
> korrekt klassifiziert.
>
> Zurück übertragen auf deine Frage mit der KI-basierten
> Softwareentwicklung: Da von einer KI derzeit nur Programme entwickelt
> werden können, die auf endlichen Eingabedaten funktionieren, kann man
> die so entwickelten Programme auch leicht daraufhin überprüfen, ob sie
> die Eingabedaten korrekt wiedergeben. Man enthält der KI einfach einen
> Teil der Eingabedaten vor und prüft anhand derer das resultierende
> Programm. Wenn die Fehlerquote signifikant über der gemäß VC-Dimension
> zu erwartenden Fehlerrate liegt, ist das Programm falsch. Und das
> war\'s dann auch schon.
>
> Der Ansatz, dass ein Mensch ein von einer KI entwickeltes Programm
> \"semantisch\" überprüft, ist nur insoweit zielführend, wie die von
> der KI entwickelten Programme überhaupt Semantik verarbeiten. Und wenn
> sie das tun, sind die Ableitungen der Regeln, die diese Programme
> vornehmen (wie in Prolog) für einen Menschen auch wieder
> nachvollziehbar.

Dann kam noch [dieser Link
rein](http://www.damninteresting.com/on-the-origin-of-circuits/) (es
geht um genetische Algorithmen im Chipdesign, Ctrl-F baffling für den
spannenden Teil)

Und zuletzt weisen einige Einsender darauf hin, dass AlphaGo mitnichten
einfach ein neuronales Netz ist, sondern schon auch \"normale\"
Monte-Carlo-Baumsuche verwendet, aber halt unterstützt mit neuronalen
Netzen. Einer kommentiert noch:

> Ich stelle mir den menschlichen Go-Spieler wie einen Ingenieur vor,
> der ohne Hilfsmittel arbeitet. Die Google-KI ist dagegen ein
> Ingenieur, der einen Rechenschieber oder einen Taschenrechner (ein an
> sich nicht intelligentes, aber schnell und präzise arbeitendes
> Hilfsmittel) direkt ins Gehirn implantiert hat.
>
> Ein Beispiel ist Zug 108 der ersten Partie gegen Lee Sedol: Dieser Zug
> ist vielleicht keiner der besonders „komischen Züge", aber ein
> menschlicher Spieler hätte diesen Zug niemals gemacht, denn er ist aus
> seiner Perspektive riskant. Die möglichen Konsequenzen sind komplex
> und vielfältig, und es ist schwierig abzuschätzen, ob wirklich alle
> sich ergebenden Varianten für den Spieler von Vorteil sind. Die
> Google-KI hingegen wirft ihren Monte-Carlo-Taschenrechner an und kann
> mit hinreichender Sicherheit feststellen, dass dieser Zug eben kein
> Fehler ist. Auf diese Weise verbindet AlphaGo die „Intuition" seiner
> neuronalen Netze mit mehr oder weniger klassischer Vorausberechnung
> der Züge.
>
> Der „Fehler" des Menschen, weshalb er verliert, ist also so gesehen,
> auf die „riskant" aussehenden, aber in Wahrheit sicheren Züge
> verzichten zu müssen und statt dessen die offensichtlich sicheren,
> aber nicht ganz so guten Züge zu spielen.

Ein Einsender hat mir noch Mut zuzusprechen versucht, indem er
Parallelen zur Mechanik zieht.

> Früher hat man mechanische Bauteile -z.B. Schubstangen oder Pleuel-
> nach Erfahrung ausgelegt. Später kam ein mathematisches Modell zur
> Beschreibung der Bauteile (Eulersche Knickfälle). Noch sehr viel
> später hat man dann das Modell nach innen gelegt (kleine Gitterzellen
> FEM) und mit den Ergebnissen daraus das äussere Modell daran
> angepasst.
>
> Wir können immer noch nicht sagen, warum dieses eine Pleuel genau an
> dieser Stelle geknickt/gebrochen ist. Wir können nur sagen, dass es
> mit hoher Wahrscheinlichkeit an dieser Stelle wegen diesem Lunker,
> dieser Kerbwirkung, dieser Resonanz versagt hat (insbesondere bei
> Resonanzen bin ich mir sicher, dass das nur ca 1/5 der Ingenieure
> versteht, bei Torsionsresonanzen nochmal die Hälfte weniger).
>
> Wir können es beschreiben, und seit einiger Zeit so gut, dass es fast
> keine weiteren Forschungsgelder mehr für Mechanik gibt, weil nichts
> grundlegend neueres erwartet wird.

und zur Frage der Debugbarkeit meint er, das ginge bei Mechanik ja auch
nicht. Da kann man das Teil nur anders auslegen und neu bauen.
