Fragen und Antworten • Re: Crawler API / Media / Parser
=======================================================

Date: 2013-11-04 18:13:55

Hi Orbiter\
\
Danke für deine ausführlichen Erklärungen.\
\
Zum Thema Mime-Type von Dokumenten hätte ich eine Idee:\
\
Das HTTP Protokoll bringt die Methode HEAD mit, das Ergebniss entspricht
einem GET aber liefert nur die Header Informationen eines Dokuments
zurück:\
\

> <div>
>
> \
> The HEAD method is identical to GET except that the server MUST NOT
> return a message-body in the response. The metainformation contained
> in the HTTP headers in response to a HEAD request SHOULD be identical
> to the information sent in response to a GET request. This method can
> be used for obtaining metainformation about the entity implied by the
> request without transferring the entity-body itself. This method is
> often used for testing hypertext links for validity, accessibility,
> and recent modification.\
>
> </div>

\
Quelle: [http://www.w3.org/Protocols/rfc2616/rfc \...
tml\#sec9.4](http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.4){.postlink}\
\
Wenn man jetzt HEAD nutzen würde, um die Header Informationen eines
Dokumentes zu bekommen, könnte man aufgrund des zurückgelieferten
mime-types entscheiden, das Dokument dann doch noch mit einem GET
komplett zu holen oder nicht, je nachdem ob der dazugehörige Parser
aktiviert ist.\
\
Der oben zitierte Text liefert eigentlich gleich noch 2 Pro\'s für einen
Einsatz der Methode HEAD: letzte Änderung des Dokuments, was vom Crawler
sicherlich genutzt wird, oder auch Links auf Existenz prüfen (Stichwort
Linkanalyse (SEO)).\
\
[Vorteile die ich sehe:]{style="text-decoration: underline"}\

-   man bekommt Header Infos ohne das gesamte Dokument holen zu müssen
-   daraus ergibt sich möglicherweise geringerer Traffic für
    Crawler-Admin und Seiten-Admin (gerade beim Crawlen von Video- oder
    Audiodateien, wäre das meiner Meinung nach ein nicht zu
    unterschätzender Vorteil)

[Nachteile die ich sehe:]{style="text-decoration: underline"}\

-   Programmieraufwand(?)
-   50% langsameres crawling, da für jedes Dokument im Zweifel 2
    requests abgesetzt werden müssten

Statistik: Verfasst von
[freak](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9007)
--- Mo Nov 04, 2013 6:13 pm

------------------------------------------------------------------------
