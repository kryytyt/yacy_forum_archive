Hilfe für Einsteiger und Anwender • Re: Web Crawler mit 0 Hops Tiefe (Webverzeichnis)
=====================================================================================

Date: 2017-09-19 09:53:38

Hallo zusammen,\
\
ich war wohl etwas voreilig. Meine Crawlerlösung scheint nicht zu
funktionieren.
![:cry:](http://forum.yacy-websuche.de/images/smilies/icon_cry.gif "Crying or Very Sad")\
\
Meine Überlegung war einen Crawl von <https://de.wikipedia.org> mit
einer Tiefe von 4 zu beginnen. (ähnlich wie die Idee von \'luc\')\
Bei \"Lade Filter auf URLs\" KEINE Einschränkung auf Startdomain und
KEINE Einschränkung auf Subpfad.\
Damit crawlt sich der Crawler erstmal durch Wikipedia verläßt aber
Wikipedia sobald er auf eine externe URL trifft.\
\
Damit wird grundsätzlich alles an Urls eingesammelt was der Crawler
finden kann. Also alle Wikipedia Urls und ALLE externen Urls die in
Wikipedia gefunden werden können.\
\
Die Einschränkung der Urls die dann dann in den \"Index Feeder\" gehen
sollen erfolgt dann in der Rubrik \"Dokument Filter\".\
\
In der Zeile:\"Filter auf Urls\" habe ich folgende Regex eingesetzt:\
\^(?:https?:\\/\\/)?(?:\[\^@\\/\\n\]+@)?(?:www\\.)?(\[\^:\\/\\n\]+)\
\
Diese Regex sollte aus allen gefunden Urls die Top-Urls ausfiltern,
damit diese UND NUR DIESE in den Index Feeder gehen sollen.\
\
Diese Regex habe ich mit etlichen Online-Regex Simulatoren getestet und
sie sollte funktionieren.\
\
Innerhalb von Yacy funktioniert sie jedoch nicht. Weder in der Crawler
Einstellung NOCH im Regex-Tester unter \"Ziel-Analyse\".\
\
Frage: Was für eine Regex muß ich im \"Dokument-Filter\" einsetzen damit
nur die Top-Urls in den Index-Feeder gehen?\
\
Gruß Alex\
\
P.S Die Regex stammt übrigens von hier\
<https://regex101.com/r/jN6kU2/1>

Statistik: Verfasst von
[Crystalgazer](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9606)
--- Di Sep 19, 2017 8:53 am

------------------------------------------------------------------------
