Fragen und Antworten • Re: Indexgröße zu extrem?
================================================

Date: 2017-07-14 18:08:07

Da sind ja mehrere solcher 50 GB Brocken, insgesamt sind das über 700 GB
![:D](http://forum.yacy-websuche.de/images/smilies/icon_e_biggrin.gif "Very Happy")\
\

> <div>
>
> \
> 10 of 100: name=\_gl4jf maxDoc=88051612\
> version=5.5.1\
> id=bk7lyqnlfkp3j53q49bd0zdsi\
> codec=Lucene54\
> compound=false\
> numFiles=13\
> size (MB)=55,742.925\
> diagnostics = {os=Linux, java.vendor=Oracle Corporation,
> java.version=1.8.0\_40, java.vm.version=25.40-b25,
> lucene.version=5.5.1, mergeMaxNumSegments=10, os.arch=amd64,
> java.runtime.version=1.8.0\_40-b26, source=merge, mergeFactor=30,
> os.version=3.16.0-4-amd64, timestamp=1469046805149}\
> has deletions \[delGen=43729\]\
> test: open reader\...\...\...OK \[took 2.418 sec\]\
> test: check integrity\.....\
>
> </div>

\
\
mergeMaxNumSegments=10 steht ja da bei der Ausgabe von Checkindex,
bedeutet das, dass sie zum nächstmöglichen Zeitpunkt gemerged werden und
dass die 12 Stunden die ich ihm Zeit gelassen habe zu wenig waren?

Statistik: Verfasst von
[LA\_FORGE](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=324)
--- Fr Jul 14, 2017 5:08 pm

------------------------------------------------------------------------
