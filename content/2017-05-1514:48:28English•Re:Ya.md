English â€¢ Re: Yacy won\'t re-start
==================================

Date: 2017-05-15 14:48:28

Increasing \"crawler.onDemandLimit\" to 50000 didn\'t work: I started
getting \"Too many open files\" error in the web frontend, I decreased
it to 5000 and again I got errors, so I reverted the value to 1000 since
I figured that probably that wasn\'t the problem anyway.\
\
I tried terminating the crawler before restarting the service and this
time it worked. I then started a new crawl using the same seed URLs but,
after 24 hours no new pages had been indexed, so I removed the index and
I started over. Now I\'m going to let the crawler run for a few days.\
\
I noticed that Yacy uses \*a lot\* of memory: I assigned 96 GB to stay
on the safe side, after 24 hours it was running steadily on 20 GB and
now (after a restart and 3 hours of crawling) it\'s already using 19 GB.
I guess it\'s normal for Java to use large amounts of memory when it\'s
available, I just wanted to let you know my experience.\
\
Another question: I installed Yacy on my laptop too, and I tried
submitting the same query on the server and on the laptop. The results
are different (I get less results on the laptop) even though
theoretically the server\'s index should be reachable since it\'s
running in \"senior mode\" (i.e. port 8090 is open on the firewall and
the server claims to be \"senior\"). Is that a behaviour to be expected?

Statistik: Verfasst von
[eros](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9756)
--- Mo Mai 15, 2017 1:48 pm

------------------------------------------------------------------------
