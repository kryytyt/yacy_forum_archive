English â€¢ Re: new page =failed. Reason: exist-test failed: Error execu
======================================================================

Date: 2016-07-13 15:48:36

HI + thanks for replying.\
I, too, just crawled that page and got this:\
Crawling of
\"http://www.theguardian.com/politics/2016/jul/11/who-will-be-in-theresa-mays-cabinet-government
\" failed. Reason: exist-test failed: Error executing query/\
\
The server in a Win vm is running as stand alone Robinson mode - public
peer\
(Microsoft Windows 10 instance in Azure cloud computing environment)\
The idea is to later convert several such Robinson servers to a
dedicated private group with full DHT+P2P in a privte group of servers
for searching a special topic\
Network definition = defaults/yacy.network.allip.unit\
\
re: used in /CrawlStartExpert.html\
generic, excepting these:\
Crawling Depth = 0\

> <div>
>
> \
> \...Use Special User Agent and robot identification\
>
> </div>

\
Use Special User Agent and robot identification = Random browser or
\'greedy\' mode\
\
As listed below\...\
Crawling Depth 1 + also all linked non-parsable documents \[selected\]\
Unlimited crawl depth for URLs matching with \[not selected\]\
Maximum Pages per Domain Use: \[not selected\] Page-Count: \[not
selected\] 10000\
misc. Constraints Accept URLs with query-part (\'?\'): \[selected\]\
Obey html-robots-noindex: \[selected\]\
Obey html-robots-nofollow: \[not selected\]\
Load Filter on URLs must-match\
Restrict to start domain(s) \[selected\]\
Restrict to sub-path(s) \[not selected\]\
Use filter.\* \[not selected\] (must not be empty)\
must-not-match\
Load Filter on IPs .\* \[not selected\] must-match(must not be empty)\
must-not-match \[not selected\]\
Must-Match List for Country Codes info no country code restriction\
Use filter \[not selected\]\
AD,AL,AT,BA,BE,BG,BY,CH,CY,CZ,DE,DK,EE,ES,FI,FO,FR,GG,GI,GR,HR,HU,IE,IM,IS,IT,JE,LI,LT,LU,LV,MC,MD,MK,MT,NL,NO,PL,PT,RO,RU,SE,SI,SJ,SK,SM,TR,UA,UK,VA,YU\
Document Filter \[not selected\]\
These are limitations on index feeder. The filters will be applied after
a web page was loaded.\
\
Filter on URLsinfo\
must-match .\* \[not selected\] (must not be empty)\
must-not-match\[not selected\]\
Filter on Content of Document \[not selected\]\
(all visible text, including camel-case-tokenized url and title)\
must-match .\* \[not selected\](must not be empty)\
must-not-match\[not selected\]\
Clean-Up before Crawl Start No Deletion Do not delete any document
before the crawl is started.\
Delete sub-path \[not selected\] For each host in the start url list,
delete all documents (in the given subpath) from that host.\
Delete only old \[not selected\] Treat documents that are loaded ago as
stale and delete them before the crawl is started.\
Double-Check Rules\
No Doubles \[selected\] Never load any page that is already known. Only
the start-url may be loaded again.\
Re-load \[not selected\] Treat documents that are loaded ago as stale
and load them again. If they are younger, they are ignored.\
Document Cache\
Store to Web Cache \[selected\]\
Policy for usage of Web Cache\
no cache \[not selected\] if fresh \[selected\] if exist \[not
selected\] cache only \[not selected\]\
Robot Behaviour\
Use Special User Agent and robot identification \[Random Browser\]\
Snapshot Creation\
Max Depth for Snapshots -1\
Multiple Snapshot Versions \[selected\>\] replace old snapshots with new
one \[not selected\] add new versions for each crawl must-not-match
filter for snapshot generation\
Index Attributes\
Indexing\
index text: {selected\] index media: \[selected\] Add Crawl result to
collection(s) user\
Time Zone Offset -120\
\
\-\--\
How and where did you get YaCy 1.91/9013 please? I\'d like to update
everything to latest ver., please, ASAP. Thanks!\
I cannot find it and the win version: 1.90/9000 update does not show it
as available, and from here it\'s somehow not in Google search.\
\
Many thanks for your patient help!

Statistik: Verfasst von
[xioc752](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=9463)
--- Mi Jul 13, 2016 2:48 pm

------------------------------------------------------------------------
