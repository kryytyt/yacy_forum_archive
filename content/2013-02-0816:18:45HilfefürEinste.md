Hilfe für Einsteiger und Anwender • Re: Crawl auf Startseiten beschränken
=========================================================================

Date: 2013-02-08 16:18:45

Vielen Dank für die ausführlichen Anworten!\
\
Klingt für mich alles logisch, wie YaCy die Punkte behandelt. (Bei
mnogosearch läuft es ein wenig anders, daher muss ich mich erst
umgewöhnen
![;)](http://forum.yacy-websuche.de/images/smilies/icon_e_wink.gif "Wink")
)\
\
Aber eines verstehe ich leider noch nicht ganz. Wenn die Start-URL
sowieso bei jedem Crawlingdurchgang neu indiziert wird, warum sollte
diese mit \"Document Deletion\" zuvor gelöscht werden? Die Seite wird ja
so und so neu indiziert und liefert entweder ein vorhandenes Dokument
oder eine Fehlerseite zurück. Oder ist das nur in meiner Situation ein
spezieller Fall, weil ich Crawlingtiefe 0 verwende und der Einsatz von
\"Document Deletion\" macht erst ab Crawlingtiefe 1 Sinn?\
\
Meine Idealvorstellung zur Erstellung eines Verzeichnisses sieht so
aus:\
1. Ausschließlich vorgegebene URLs aus Liste indizieren\
2. Regelmäßige Aktualisierung, zB Recrawl alle 7 Tage\
3. Wenn Fehlerseite zurückgeliefert wird, alten Seiteninhalt behalten
(weil evtl. wichtig für Verzeichnis und nur zufällig gerade nicht
erreichbar)\
4. Dokument erst als Fehlerseite ablegen wenn zB 3x nicht verfügbar.\
\
Evtl. irgendeine Idee, wie Pkt. 3 und 4 realisierbar wären?

Statistik: Verfasst von
[hotel24](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=8871)
--- Fr Feb 08, 2013 4:18 pm

------------------------------------------------------------------------
