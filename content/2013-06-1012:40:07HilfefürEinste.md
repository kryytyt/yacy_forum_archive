Hilfe für Einsteiger und Anwender • Re: Alle Crawls lediglich auf eine bestimmte Domäne beschrän
================================================================================================

Date: 2013-06-10 12:40:07

> <div>
>
> mbehrens hat geschrieben:\
> Bei uns taucht leider immer wieder das Problem auf, dass der Crawler
> aus irgendwelchen Gründen anfängt, quasi \'das gesamte Web\'
> abzugrasen (was wir definitiv nicht wollen).\
>
> </div>

\
die Crawl-regex habe ich jetzt schon öfters kontrolliert und glaube dass
sie nichts unerwünschtes durchlassen. Ich müsste mir da mal ein
konkretes Beispiel angucken.\
\

> <div>
>
> mbehrens hat geschrieben:\
> Ich habe schon überlegt, ob ich sie mal alle lösche und stattdessen
> mit einem einzigen HTML-Dokument als Crawl-Start arbeite, aber eine
> \'globale Whitelist\' würde das Problem sicher auch lösen.\
>
> </div>

\
ich weiss, die GSA arbeitet so. Da gibts eine Liste mit Startpunkt-URLs
und eine große Regex-Liste. Man kann das in YaCy so ähnlich machen, es
ist möglich mehrere URLs als Startpunkt anzugeben und die \'große
regex-Liste\' kann man durch eine geeignete Disjunktion der
Einzel-regexe realisieren.\
\
In diesem Sinne ist YaCy aber wesentlich flexibler als die GSA, weil man
eben diese eine große Liste in einzelne Crawls unterteilen kann und
denen auch noch automatische Durchführungszyklem im Process Steering
zuordnen kann. Die GSA macht das ja nur \'wenn sie denkt das es an der
Zeit ist\', so weit ich weiss, kann man das nicht beeinflussen.

Statistik: Verfasst von
[Orbiter](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=2)
--- Mo Jun 10, 2013 11:40 am

------------------------------------------------------------------------
