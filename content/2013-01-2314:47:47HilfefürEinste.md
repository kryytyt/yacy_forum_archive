Hilfe für Einsteiger und Anwender • Re: Crawl auf Startseiten beschränken
=========================================================================

Date: 2013-01-23 14:47:47

Vielen Dank für die Antworten, das hilft mir sehr weiter!
![:)](http://forum.yacy-websuche.de/images/smilies/icon_e_smile.gif "Smile")\
\
Durch mehrere Tests erscheint es mir so, als ob der Crawler bei einer
\"301 Weiterleitung\" nicht die angegebene Starturl, sondern die über
die Weiterleitung aufgerufene Seite indiziert. Dies hat mich
offensichtlich eingangs verwirrt, da ich dachte, dass dazu Crawling
Depth 1 notwendig wäre. Daher sind wohl auch Urls im Index aufgetaucht,
die nicht in meiner Urlliste eingetragen sind.\
\
Die robots.txt wird scheinbar standardmäßig bei jeder Url aufgerufen und
wird diese dann, wenn vorhanden, ebenfalls indiziert? Denn bei einem
Test mit 1000 Urls waren letztendlich 1.376 Urls im Index, trotz
Crawling Depth 0.\
\
Mit der Liste von 20.000 Urls treten 2 unterschiedliche Ergebnisse auf:
Manchmal hängt sich das System auf, manchmal funktioniert das Crawling,
aber es werden nur rd. die Hälfte der Seiten indiziert.

Statistik: Verfasst von
[hotel24](http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&u=8871)
--- Mi Jan 23, 2013 2:47 pm

------------------------------------------------------------------------
