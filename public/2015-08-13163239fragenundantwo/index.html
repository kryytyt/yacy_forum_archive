<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.37.1" />
  <title> &middot; Yacy Old Forum Archiv</title>
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">
  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->
  <!--[if lte IE 8]>
  <link rel="stylesheet" href="/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="/css/side-menu.css">
  <!--<![endif]-->
  <link rel="stylesheet" href="/css/blackburn.css">
  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
 
  
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
  
  
</head>
<body>
<div id="layout">
  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">
  
  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
    </ul>
  </div>
  <div class="pure-menu social">
  <ul class="pure-menu-list">
    
    
    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/http://twitter.com/yacy_search" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yacy" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>
  <div>
  <div class="small-print">
    <small></small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>
</div>
  <div id="main">
<div class="header">
  <h1></h1>
  <h2></h2>
</div>
<div class="content">
  
<h1 id="fragen-und-antworten-crawler-verwirft-seiten-wenn-remote-proxy-offline">Fragen und Antworten • Crawler verwirft Seiten, wenn Remote-Proxy offline</h1>
<p>Date: 2015-08-13 16:32:39</p>
<p>(YaCy version 1.<sup>83</sup>&frasl;<sub>9289</sub>)<br />
<br />
Hallo!<br />
<br />
[Ausgangslage:]{style=&ldquo;text-decoration: underline&rdquo;} Ich lasse mein YaCy
über einen Remote-Proxy (privoxy) crawlen, damit keine Werbung indiziert
wird.<br />
<br />
[Problem: ]{style=&ldquo;text-decoration: underline&rdquo;} Ist der Proxy nicht
erreichbar, verwirft der Crawler systematisch URLs aus der
Warteschlange. Ich gehe davon aus, dass hier einfach das Timeout wirkt.
Nun habe ich aber unter /Settings_p.html?page=crawler das Timeout auf 0
gestellt. Da steht, dass das Timeout dann unendlich ist. Dann dürften
die URLs nicht verworfen werden, sondern müssten einfach warten, bis die
Verbindung wieder da ist. Oder habe ich das falsch verstanden?<br />
<br />
[Problematische Wirkung: ]{style=&ldquo;text-decoration: underline&rdquo;}Wenn ein
Crawl in der Tiefe einer Domain unterbrochen wird und die Warteschlange
sich leert, fehlen die URLs um vom bisheriegen Crawl-Zustand weiter zu
gehen. Sprich: Der Crawl beendet sich. Ich müsste ihn, obwohl ich schon
viele 100 Megabyte ercrawlt und indiziert habe, wieder von ganz oben
suchen lassen. Sprich: Es geht von vorn los. Und das bei derzeit einigen
10 Startadressen, die als Crawls über Tage parallel laufen.<br />
<br />
Wie kann man das Crawln zum automatischen Halt bringen, ohne dass URLs
verworfen werden? Dafür ist doch eigentlich das Timeout=0 da. Oder? Gibt
es da ein anderes Schalterchen?<br />
<br />
Auch problematisch: Wenn ich mich nicht darauf verlassen kann, dass
Crawls vollständig durchlaufen und bei zeitweisen Verbindungsproblemen
warten, kann ich nie sicher sein, ein bestimmtes Ziel tatsächlich
vollständig indiziert zu haben. Das gilt nicht nur auf den
eingeschleiften Proxy bezogen, sondern auch auf die Internetverbindung
und eventuelle Server-Down-Zustände der Zieldomains.<br />
<br />
Gibt es Möglichkeiten, aus dieser Misere heraus zu kommen?<br />
<br />
Viele Grüße<br />
Frank</p>
<p>Statistik: Verfasst von
<a href="http://forum.yacy-websuche.de/memberlist.php?mode=viewprofile&amp;u=9031">fherb</a>
&mdash; Do Aug 13, 2015 3:32 pm</p>
<hr />
</div>
</div>
</div>
<script src="js/ui.js"></script>
</body>
</html>
