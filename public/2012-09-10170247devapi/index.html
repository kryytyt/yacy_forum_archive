<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.37.1" />

  <title> &middot; Yacy Old Forum Archiv</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  

  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  

  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/http://twitter.com/yacy_search" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yacy" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small></small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1></h1>
  <h2></h2>
</div>
<div class="content">
  

<h1 id="dev-api">Dev:API</h1>

<p>Date: 2012-09-10 17:02:47</p>

<p>[Understanding YaCy crawl profiles: ]{.autocomment}</p>

<p>← Nächstältere Version</p>

<p>Version vom 10. September 2012, 15:02 Uhr</p>

<p>(3 dazwischenliegende Versionen von einem Benutzer werden nicht
angezeigt)</p>

<p>Zeile 612:</p>

<p>Zeile 612:</p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingMode\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingMode\'\'\' =  

</div>

<p>−</p>

<div>

\| The crawler can be started with different modes~~.~~

</div>

<p>+</p>

<div>

\| [Possible values: \'url\', \'sitemap\', \'sitelist\',
\'file\'.]{.underline} The crawler can be started with different
modes[:]{.underline}

</div>

<p>−</p>

<div>

\*url: start from a given url which is the root of a crawl tree. The url
is given in \'crawlingURL\'. If this url is a http-link, then the Crawl
will subsequently load all linked documents from http until a given
depth is reached. If this url is a smb- or ftp-link, then the given
resource will be listed completely using a special listing process.

</div>

<p>+</p>

<div>

\*[\']{.underline}url[\']{.underline}: start from a given url which is
the root of a crawl tree. The url is given in \'crawlingURL\'. If this
url is a http-link, then the Crawl will subsequently load all linked
documents from http until a given depth is reached. If this url is a
smb- or ftp-link, then the given resource will be listed completely
using a special listing process.

</div>

<p>−</p>

<div>

\*sitemap: use a sitemap to retrieve all files that are listed in the
sitemap. The sitemap-URL is given in \'sitemapURL\'

</div>

<p>+</p>

<div>

\*[\']{.underline}sitemap[\']{.underline}: use a sitemap to retrieve all
files that are listed in the sitemap. The sitemap-URL is given in
\'sitemapURL\'

</div>

<p>−</p>

<div>

\*sitelist: use a list of crawl start URLs. This is like starting with
one url, but using several of them. The list of urls is retrieved by
loading the url given in \'crawlingURL\'. Each of the urls in that file
is then used to start it\'s individual crawl. This makes sense if the
\'range\' attribute contains the value \'domain\' or \'subpath\' which
creates an individual must-match pattern for each of the urls in the
sitelist.

</div>

<p>+</p>

<div>

\*[\']{.underline}sitelist[\']{.underline}: use a list of crawl start
URLs. This is like starting with one url, but using several of them. The
list of urls is retrieved by loading the url given in \'crawlingURL\'.
Each of the urls in that file is then used to start it\'s individual
crawl. This makes sense if the \'range\' attribute contains the value
\'domain\' or \'subpath\' which creates an individual must-match pattern
for each of the urls in the sitelist.

</div>

<p>−</p>

<div>

\*file: use a file in the local file system to provide a start document.
The crawl will then start like with a root url but the file itself will
not be placed to the index, only the documents which are linked in that
document.

</div>

<p>+</p>

<div>

\*[\']{.underline}file[\']{.underline}: use a file in the local file
system to provide a start document. The crawl will then start like with
a root url but the file itself will not be placed to the index, only the
documents which are linked in that document.

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingURL\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingURL\'\'\' =  

</div>

<p>Zeile 622:</p>

<p>Zeile 622:</p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'sitemapURL\'\'\' =

</div>

<p> </p>

<div>

\|\'\'\'sitemapURL\'\'\' =

</div>

<p>−</p>

<div>

\|~~A~~ url ~~that~~ is typically linked within a robots.txt file. The
sitemapURL must point to a resource which is formed as described in
http://www.sitemaps.org

</div>

<p>+</p>

<div>

\|[Only to be defined if \'crawlingMode\' = \'sitemap\'. This is
an]{.underline} url [which]{.underline} is typically linked within a
robots.txt file. The sitemapURL must point to a resource which is formed
as described in http://www.sitemaps.org

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingFile\'\'\' =

</div>

<p> </p>

<div>

\|\'\'\'crawlingFile\'\'\' =

</div>

<p>−</p>

<div>

\|~~A~~ path to the local file system.

</div>

<p>+</p>

<div>

\|[Only to be defined if \'crawlingMode\' = \'file\'. This is
a]{.underline} path to [a file in]{.underline} the local file system[.
The content of the file is parsed and all urls inside that document are
roots for crawl starts as defined in this crawl request]{.underline}.

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingDepth\'\'\' =

</div>

<p> </p>

<div>

\|\'\'\'crawlingDepth\'\'\' =

</div>

<p> </p>

<div>

\|This defines how often the Crawler will follow links embedded in
websites.

</div>

<p> </p>

<div>

\|This defines how often the Crawler will follow links embedded in
websites.

</div>

<p> </p>

<div>

A minimum of 0 is recommended and means that the page set as crawling
URL, sitemap orfile will be added to the index, but no linked content is
indexed. 2-4 is good for normal indexing. Be careful with the depth,
consider a branching factor of average 20; A prefetch-depth of 8 would
index 25.600.000.000 pages, maybe this is the whole WWW.

</div>

<p> </p>

<div>

A minimum of 0 is recommended and means that the page set as crawling
URL, sitemap orfile will be added to the index, but no linked content is
indexed. 2-4 is good for normal indexing. Be careful with the depth,
consider a branching factor of average 20; A prefetch-depth of 8 would
index 25.600.000.000 pages, maybe this is the whole WWW.

</div>

<p> </p>

<p>+</p>

<div>

[\|-]{.underline}

</div>

<p> </p>

<p>+</p>

<div>

[\|\'\'\'range\'\'\' =]{.underline}

</div>

<p> </p>

<p>+</p>

<div>

[\|Possible values are \'domain\', \'subpath\' or not set, which means
\'wide\'. Default is \'wide\'. If this value is set to \'domain\' or
\'subpath\', the \'mustmatch\' parameter is set automatically and
overrides given values in that field. \'domain\' creates a \'mustmatch\'
value which restricts the crawl to pages on the same domain of the
start-url; \'subpath\' creates a \'mustmatch\' value which restricts the
crawl to pages within the same subpath of the start-url.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'mustmatch\'\'\' =

</div>

<p> </p>

<div>

\|\'\'\'mustmatch\'\'\' =

</div>

<p> </p>

<div>

\|The filter is a
\[http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html
regular expression\] that must match with the URLs which are used to be
crawled; default is \'catch all\'. \<br\>Example: to allow only urls
that contain the word \'science\', the filter is set to
\'.\*science.\*\'. An automatic domain-restriction can be used to fully
crawl a single domain.

</div>

<p> </p>

<div>

\|The filter is a
\[http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html
regular expression\] that must match with the URLs which are used to be
crawled; default is \'catch all\'. \<br\>Example: to allow only urls
that contain the word \'science\', the filter is set to
\'.\*science.\*\'. An automatic domain-restriction can be used to fully
crawl a single domain.

</div>

<p>−</p>

<div>

~~\|-~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|\'\'\'range\'\'\' =~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|~~

</div>

<p> </p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'mustnotmatch\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'mustnotmatch\'\'\' =  

</div>

<p>Zeile 641:</p>

<p>Zeile 641:</p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderCheck\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderCheck\'\'\' =  

</div>

<p>−</p>

<div>

\|~~If this option~~ is ~~used,~~ web pages that are already existent in
the peers database are crawled and indexed again. It depends on the age
of the last crawl if this is done or not: if the last crawl is older
than the given date, the page is crawled again, otherwise it is treated
as \'double\' and not loaded or indexed again.

</div>

<p>+</p>

<div>

\|[value]{.underline} is [either \'on\' or \'off\'; default is \'off\'.
If \'on\'.]{.underline} web pages that are already existent in the peers
database are crawled and indexed again. It depends on the age of the
last crawl if this is done or not: if the last crawl is older than the
given date, the page is crawled again, otherwise it is treated as
\'double\' and not loaded or indexed again.

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderNumber\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderNumber\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\|[If \'crawlingIfOrderCheck\' is \'on\', then this must be set with a
numeric value. The unit is given in field
\'crawlingIfOlderUnit\'.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderUnit\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingIfOlderUnit\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\| [Possible values are \'year\', \'month\', \'day\',
\'hour\']{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingDomMaxCheck\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingDomMaxCheck\'\'\' =  

</div>

<p>Zeile 653:</p>

<p>Zeile 653:</p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingDomMaxPages\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingDomMaxPages\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\|[Integer values are allowed. If this value is given, then the maximum
number of pages per domain is restricted to this given
number.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlingQ\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlingQ\'\'\' =  

</div>

<p>−</p>

<div>

\|A questionmark is usually a hint for a dynamic page. URLs pointing to
dynamic content should usually not be crawled. However, there are
sometimes web pages with static content that is accessed with URLs
containing question marks.  

</div>

<p>+</p>

<div>

\|[value is either \'on\' or \'off\'; default is \'off\'.]{.underline} A
questionmark is usually a hint for a dynamic page. URLs pointing to
dynamic content should usually not be crawled. However, there are
sometimes web pages with static content that is accessed with URLs
containing question marks.  

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'storeHTCache\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'storeHTCache\'\'\' =  

</div>

<p>−</p>

<div>

\|~~This option~~ is ~~used by~~ default ~~for proxy prefetch~~, ~~but~~
is ~~not needed for explicit crawling~~.

</div>

<p>+</p>

<div>

\|[value]{.underline} is [either \'on\' or \'off\';]{.underline} default
[is \'on\'. If \'on\']{.underline}, [all downloaded content]{.underline}
is [stored in a built-in cache, the HTCache]{.underline}.

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'cachePolicy\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'cachePolicy\'\'\' =  

</div>

<p>−</p>

<div>

\|The caching policy states when to ~~use~~ the ~~cache~~ during
crawling:

</div>

<p>+</p>

<div>

\|The caching policy states when to [read from]{.underline} the
[HTCache]{.underline} during crawling:

</div>

<p> </p>

<div>

\*no cache: never use the cache, all content from fresh internet source;

</div>

<p> </p>

<div>

\*no cache: never use the cache, all content from fresh internet source;

</div>

<p> </p>

<div>

\*if fresh: use the cache if the cache exists and is fresh using the
proxy-fresh rules;

</div>

<p> </p>

<div>

\*if fresh: use the cache if the cache exists and is fresh using the
proxy-fresh rules;

</div>

<p>Zeile 669:</p>

<p>Zeile 669:</p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'indexText\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'indexText\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\|[value is either \'on\' or \'off\'; default is \'on\'. If this is
\'on\' then the fulltext is indexed. If \'off\', only the metadata of
the pages or media according to \'indexMedia\' is recorded and
indexed.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'indexMedia\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'indexMedia\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\|[value is either \'on\' or \'off\'; default is \'on\'.  If this is
\'on\' then the metadta (if available) of media content. If \'off\',
only the metadata of the pages or fulltext according to \'indexText\' is
recorded and indexed.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'crawlOrder\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'crawlOrder\'\'\' =  

</div>

<p>−</p>

<div>

\|If ~~checked,~~ the crawler will contact other peers and use them as
remote indexers for your crawl. If crwling results are needed locally,
this switch should be set to false. Only senior and principal peers can
initiate or receive remote crawls. A YaCyNews message will be created to
inform all peers about a global crawl, so they can omit starting a crawl
with the same start point.

</div>

<p>+</p>

<div>

\|[value is either \'on\' or \'off\'; default is \'off\'.]{.underline}
If [\'on\']{.underline} the crawler will contact other peers and use
them as remote indexers for your crawl. If crwling results are needed
locally, this switch should be set to false. Only senior and principal
peers can initiate or receive remote crawls. A YaCyNews message will be
created to inform all peers about a global crawl, so they can omit
starting a crawl with the same start point.

</div>

<p> </p>

<div>

\|-  

</div>

<p> </p>

<div>

\|-  

</div>

<p> </p>

<div>

\|\'\'\'intention\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'intention\'\'\' =  

</div>

<p>−</p>

<div>

\|

</div>

<p>+</p>

<div>

\|[This is a text message that is posted along with the crawlOrder
option to inform other YaCy peers about a distributed crawl. If
\'crawlOrder\' is \'off\', this value is not used.]{.underline}

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'xsstopw\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'xsstopw\'\'\' =  

</div>

<p> </p>

<div>

\|This can be useful to circumvent that extremely common words are added
to the database, i.e. \"the\", \"he\", \"she\", \"it\"\... To exclude
all words given in the file \<tt\>yacy.stopwords\</tt\> from indexing,
this hast to be set true.

</div>

<p> </p>

<div>

\|This can be useful to circumvent that extremely common words are added
to the database, i.e. \"the\", \"he\", \"she\", \"it\"\... To exclude
all words given in the file \<tt\>yacy.stopwords\</tt\> from indexing,
this hast to be set true.

</div>

<p>−</p>

<div>

~~\|-~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|\'\'\'xdstopw\'\'\' =~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|-~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|\'\'\'xpstopw\'\'\' =~~

</div>

<p> </p>

<p>−</p>

<div>

~~\|~~

</div>

<p> </p>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|-

</div>

<p> </p>

<div>

\|\'\'\'collection\'\'\' =  

</div>

<p> </p>

<div>

\|\'\'\'collection\'\'\' =  

</div>

</div>

</div>
</div>
<script src="js/ui.js"></script>






</body>
</html>

